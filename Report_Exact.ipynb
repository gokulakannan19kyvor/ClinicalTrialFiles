{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Report-Exact.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgokulakannankg19/ClinicalTrialFiles/blob/main/Report_Exact.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSEDEILwbxNc"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gspread"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gspread-formatting"
      ],
      "metadata": {
        "id": "yhVhB14zcMdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "from datetime import date\n",
        "\n",
        "import gspread\n",
        "\n",
        "from gspread_formatting import *\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "metadata": {
        "id": "2IPxiRa6cBME"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gene_aliases_from_master_genes(gene):\n",
        "  gene = gene\n",
        "  wb_master_gene = gc.open_by_key(\"1KvrHR3ShutWfOHvXYvyWn44B4FggKvA2b9Wy8RSad1E\")\n",
        "\n",
        "  ws_compilations = wb_master_gene.worksheet('COMPILATION')\n",
        "  rows = ws_compilations.get_all_values()\n",
        "\n",
        "  df_compilations = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "\n",
        "  new_df = df_compilations.set_index('Gene')\n",
        "  gene_name_results = new_df.loc[gene, 'Aliases-Final List': 'SEARCH TERMS']\n",
        "\n",
        "  gene_names = []\n",
        "\n",
        "  gene_name_alias_list = gene_name_results['Aliases-Final List'].split('|')\n",
        "  gene_name_searchterms = gene_name_results['SEARCH TERMS'].split('|')\n",
        "\n",
        "  gene_names = gene_name_alias_list + gene_name_searchterms\n",
        "  gene_names = [gene.strip() for gene in gene_names]\n",
        "  \n",
        "  if \"\" in gene_names:\n",
        "    gene_names.remove(\"\")\n",
        "  \n",
        "  return gene_names"
      ],
      "metadata": {
        "id": "ImrLbpLIceOd"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_cancer_nct_id(final_combined_df):\n",
        "  result_list = [] \n",
        "  for index in final_combined_df.index: \n",
        "  \n",
        "    trial_rows=[]\n",
        "    cancer_found_in = []\n",
        "    cancers_found_list = []\n",
        "    \n",
        "    \n",
        "    data_df = final_combined_df.loc[index]\n",
        "\n",
        "    nct_id = data_df['NCT ID']\n",
        "    study_type = data_df['Study Type']\n",
        "    overall_status = data_df['Recruitment Status']\n",
        "    phase = data_df['Phase']\n",
        "    brief_title = data_df['Brief Title']\n",
        "    official_title = data_df['Official Title']\n",
        "    brief_summary = data_df['Brief Summary']\n",
        "    detailed_description = data_df['Detailed Description']\n",
        "    cancer_type = data_df['Cancer Type']\n",
        "    study_purpose = data_df['Study Purpose']\n",
        "    intervention = data_df['Intervention']\n",
        "    intervention_description = data_df['Intervention Description']\n",
        "    intervention_other_name = data_df['Intervention Other Name']\n",
        "    study_model = data_df['Study Model']\n",
        "    arm_title = data_df['Arm Title']\n",
        "    arm_description = data_df['Arm Description']\n",
        "    arm_group_intervention = data_df['Arm Group Intervention']\n",
        "    eligibility_criteria = data_df['Eligibility Criteria']\n",
        "    inclusion_criteria = data_df['Inclusion Criteria']\n",
        "    exclusion_criteria = data_df['Exclusion Criteria']\n",
        "    keywords = data_df['Keywords']\n",
        "    pmid = data_df['PMID']\n",
        "    url = data_df['URL']\n",
        "    primary_om_title = data_df['Primary OM Title']\n",
        "    primary_om_description = data_df['Primary OM Description']\n",
        "    secondary_om_title = data_df['Secondary OM Title']\n",
        "    secondary_om_description = data_df['Secondary OM Description']\n",
        "    other_om_title = data_df['Other OM Title']\n",
        "    other_om_description = data_df['Other OM Description']\n",
        "    mesh_terms = data_df['MeSH Terms']\n",
        "    character_count = data_df['Character Count']\n",
        "\n",
        "    cancer_list = [\"cancer\", \"neoplasm\", \"tumor\", \"malignancy\", \"oncology\", \"neoplasia\", \"neoplastic syndrome\", \"neoplastic disease\"]\n",
        "\n",
        "    column_list = ['study_type', 'phase', 'brief_title', 'official_title', 'brief_summary', 'detailed_description', 'cancer_type', 'study_purpose', 'intervention', 'intervention_description', 'intervention_other_name', 'study_model', 'arm_title', 'arm_description', 'arm_group_intervention', 'eligibility_criteria', 'primary_om_title', 'primary_om_description', 'secondary_om_title', 'secondary_om_description', 'other_om_title', 'other_om_description', 'mesh_terms']\n",
        "\n",
        "\n",
        "    for cancer in cancer_list:\n",
        "      cancer = cancer.lower()\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), study_type.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Study Type\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), brief_title.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Brief Title\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), official_title.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Official Title\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), brief_summary.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Brief Summary\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), detailed_description.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Detailed Description\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), cancer_type.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Cancer Type\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), intervention_description.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Intervention Description\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), intervention_other_name.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Intervention Other Name\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), arm_description.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Arm Description\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), eligibility_criteria.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Eligibility Criteria\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), inclusion_criteria.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Inclusion Criteria\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), exclusion_criteria.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Exclusion Criteria\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), keywords.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Keywords\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), primary_om_title.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Primary OM Title\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), primary_om_description.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Primary OM Description\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), secondary_om_title.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Secondary OM Title\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), secondary_om_description.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Secondary OM Description\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), other_om_title.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Other OM Title\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), other_om_description.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = Other OM Description\")\n",
        "        cancers_found_list.append(cancer)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(cancer), mesh_terms.lower())):\n",
        "        cancer_found_in.append(f\"{cancer} = MeSH Terms\")\n",
        "        cancers_found_list.append(cancer)"
      ],
      "metadata": {
        "id": "fMUtykOoTp2a"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_gene_found_in(sheet_df, gene_names):\n",
        "\n",
        "  # Sheet for drug pathway sheet\n",
        "  \n",
        "  # target_pathway_sh = gc.open_by_key(\"1_2AUMO9fLDVWoBF-DNgw6iBzr4uzwsbV6mJv-KzP1Yk\")\n",
        "  # target_pathway_sheet = target_pathway_sh.worksheet(\"PIK3CA\")\n",
        "  # target_pathway_rows = target_pathway_sheet.get_all_values()\n",
        "\n",
        "  # target_pathway_df = pd.DataFrame(target_pathway_rows[1:], columns=target_pathway_rows[0])\n",
        "  \n",
        "  # ----------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "  # Sheet for variant\n",
        "\n",
        "  # variant_sh = gc.open_by_key(\"1_hKejRNMKYEf4jPQYSvzJZZUHIm-eNDDcuyc8LB6L5M\")\n",
        "  # variant_sheet = variant_sh.worksheet('Oncogene')\n",
        "  # variant_rows = variant_sheet.get_all_values()\n",
        "\n",
        "  # variant_df = pd.DataFrame(variant_rows[1:], columns=variant_rows[0])\n",
        "\n",
        "  # data = variant_df.loc[(variant_df.Gene == gene_name)]\n",
        "  # variant_names = data['Variant'].to_numpy().tolist()\n",
        "  \n",
        "  # -------------------------------------------------------------------------------------------------\n",
        "\n",
        "  result_list = [] \n",
        "  for index in sheet_df.index: \n",
        "  \n",
        "    trial_rows=[]\n",
        "    gene_found_in = []\n",
        "    genes_found_list = []\n",
        "    variant_found_in = []\n",
        "    variants_found_list = []\n",
        "    mutant_found_in = []\n",
        "    wild_type_found_in = []\n",
        "    \n",
        "    data_df = sheet_df.loc[index]\n",
        "  \n",
        "    \n",
        "    nct_id = data_df['NCT ID']\n",
        "    study_type = data_df['Study Type']\n",
        "    overall_status = data_df['Recruitment Status']\n",
        "    phase = data_df['Phase']\n",
        "    brief_title = data_df['Brief Title']\n",
        "    official_title = data_df['Official Title']\n",
        "    brief_summary = data_df['Brief Summary']\n",
        "    detailed_description = data_df['Detailed Description']\n",
        "    cancer_type = data_df['Cancer Type']\n",
        "    study_purpose = data_df['Study Purpose']\n",
        "    intervention = data_df['Intervention']\n",
        "    intervention_description = data_df['Intervention Description']\n",
        "    intervention_other_name = data_df['Intervention Other Name']\n",
        "    study_model = data_df['Study Model']\n",
        "    arm_title = data_df['Arm Title']\n",
        "    arm_description = data_df['Arm Description']\n",
        "    arm_group_intervention = data_df['Arm Group Intervention']\n",
        "    eligibility_criteria = data_df['Eligibility Criteria']\n",
        "    inclusion_criteria = data_df['Inclusion Criteria']\n",
        "    exclusion_criteria = data_df['Exclusion Criteria']\n",
        "    keywords = data_df['Keywords']\n",
        "    pmid = data_df['PMID']\n",
        "    url = data_df['URL']\n",
        "    primary_om_title = data_df['Primary OM Title']\n",
        "    primary_om_description = data_df['Primary OM Description']\n",
        "    secondary_om_title = data_df['Secondary OM Title']\n",
        "    secondary_om_description = data_df['Secondary OM Description']\n",
        "    other_om_title = data_df['Other OM Title']\n",
        "    other_om_description = data_df['Other OM Description']\n",
        "    mesh_terms = data_df['MeSH Terms']\n",
        "    character_count = data_df['Character Count']\n",
        "\n",
        "    # ---------------------------------------FOR GENE FOUND IN LIST ---------------------------------------\n",
        "\n",
        "    for gene in gene_names:\n",
        "      gene = gene.lower()\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), brief_title.lower())):\n",
        "        gene_found_in.append(f\"{gene} = Brief Title\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), official_title.lower())):\n",
        "        gene_found_in.append(f\"{gene} = Official Title\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), brief_summary.lower())):\n",
        "        gene_found_in.append(f\"{gene} = Brief Summary\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), detailed_description.lower())):\n",
        "        # print(\"found\", \"Detailed Description\")\n",
        "        gene_found_in.append(f\"{gene} = Detailed Description\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), cancer_type.lower())):\n",
        "        # print(\"found\", \"Cancer Type\")\n",
        "        gene_found_in.append(f\"{gene} = Cancer Type\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), intervention_description.lower())):\n",
        "        # print(\"found\", \"Intervention Description\")\n",
        "        gene_found_in.append(f\"{gene} = Intervention Description\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), arm_title.lower())):\n",
        "        # print(\"found\", \"Arm Title\")\n",
        "        gene_found_in.append(f\"{gene} = Arm Title\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), arm_description.lower())):\n",
        "        # print(\"found\", \"Arm Description\")\n",
        "        gene_found_in.append(f\"{gene} = Arm Description\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), eligibility_criteria.lower())):\n",
        "        # print(\"found\", \"Eligibility Criterial\")\n",
        "        gene_found_in.append(f\"{gene} = Eligibility Criteria\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), inclusion_criteria.lower())):\n",
        "        # print(\"found\", \"Inclusion Criteria\")\n",
        "        gene_found_in.append(f\"{gene} = Inclusion Criteria\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), exclusion_criteria.lower())):\n",
        "        # print(\"found\", \"Exclusion Criteria\")\n",
        "        gene_found_in.append(f\"{gene} = Exclusion Criteria\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), keywords.lower())):\n",
        "        # print(\"found\", \"Keywords\")\n",
        "        gene_found_in.append(f\"{gene} = Keywords\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), primary_om_title.lower())):\n",
        "        # print(\"found\", \"Primary OM Title\")\n",
        "        gene_found_in.append(f\"{gene} = Primary OM Title\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), primary_om_description.lower())):\n",
        "        # print(\"found\", \"Primary OM Description\")\n",
        "        gene_found_in.append(f\"{gene} = Primary OM Description\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), secondary_om_title.lower())):\n",
        "        # print(\"found\", \"Secondary OM Title\")\n",
        "        gene_found_in.append(f\"{gene} = Secondary OM Title\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), secondary_om_description.lower())):\n",
        "        # print(\"found\", \"Secondary OM Description\")\n",
        "        gene_found_in.append(f\"{gene} = Secondary OM Description\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), other_om_title.lower())):\n",
        "        # print(\"found\", \"Other OM Title\")\n",
        "        gene_found_in.append(f\"{gene} = Other OM Title\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), other_om_description.lower())):\n",
        "        # print(\"found\", \"Other OM Description\")\n",
        "        gene_found_in.append(f\"{gene} = Other OM Description\")\n",
        "        genes_found_list.append(gene)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(gene), mesh_terms.lower())):\n",
        "        # print(\"found\", \"MeSH Terms\")\n",
        "        gene_found_in.append(f\"{gene} = MeSH Terms\")\n",
        "        genes_found_list.append(gene)\n",
        "\n",
        "\n",
        "    gene_found_in_string = \" | \".join(gene_found_in)\n",
        "    gene_found_in_list = gene_found_in_string.split(\" | \")\n",
        "\n",
        "    genes_found_list = list(set(genes_found_list))\n",
        "    genes_found_string = \" | \".join(genes_found_list)\n",
        "\n",
        "    # print(\"gene found in completed\")\n",
        "\n",
        "\n",
        "    # ------------------------------------For variant list ----------------------------------------------\n",
        "\n",
        "    # for variant in variant_names:\n",
        "    #   variant = variant.lower()\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), brief_title.lower())):\n",
        "    #     # print(\"found\", \"Brief Title\")\n",
        "    #     variant_found_in.append(f\"{variant} = Brief Title\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), official_title.lower())):\n",
        "    #     # print(\"found\", \"Official Title\")\n",
        "    #     variant_found_in.append(f\"{variant} = Official Title\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), brief_summary.lower())):\n",
        "    #     # print(\"found\", \"Brief Summary\")\n",
        "    #     variant_found_in.append(f\"{variant} = Brief Summary\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), detailed_description.lower())):\n",
        "    #     # print(\"found\", \"Detailed Description\")\n",
        "    #     variant_found_in.append(f\"{variant} = Detailed Description\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), cancer_type.lower())):\n",
        "    #     # print(\"found\", \"Cancer Type\")\n",
        "    #     variant_found_in.append(f\"{variant} = Cancer Type\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), intervention_description.lower())):\n",
        "    #     # print(\"found\", \"Intervention Description\")\n",
        "    #     variant_found_in.append(f\"{variant} = Intervention Description\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), arm_title.lower())):\n",
        "    #     # print(\"found\", \"Arm Title\")\n",
        "    #     variant_found_in.append(f\"{variant} = Arm Title\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), arm_description.lower())):\n",
        "    #     # print(\"found\", \"Arm Description\")\n",
        "    #     variant_found_in.append(f\"{variant} = Arm Description\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), eligibility_criteria.lower())):\n",
        "    #     # print(\"found\", \"Eligibility Criterial\")\n",
        "    #     variant_found_in.append(f\"{variant} = Eligibility Criteria\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), inclusion_criteria.lower())):\n",
        "    #     # print(\"found\", \"Inclusion Criteria\")\n",
        "    #     variant_found_in.append(f\"{variant} = Inclusion Criteria\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), exclusion_criteria.lower())):\n",
        "    #     # print(\"found\", \"Exclusion Criteria\")\n",
        "    #     variant_found_in.append(f\"{variant} = Exclusion Criteria\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), keywords.lower())):\n",
        "    #     # print(\"found\", \"Keywords\")\n",
        "    #     variant_found_in.append(f\"{variant} = Keywords\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), primary_om_title.lower())):\n",
        "    #     # print(\"found\", \"Primary OM Title\")\n",
        "    #     variant_found_in.append(f\"{variant} = Primary OM Title\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), primary_om_description.lower())):\n",
        "    #     # print(\"found\", \"Primary OM Description\")\n",
        "    #     variant_found_in.append(f\"{variant} = Primary OM Description\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), secondary_om_title.lower())):\n",
        "    #     # print(\"found\", \"Secondary OM Title\")\n",
        "    #     variant_found_in.append(f\"{variant} = Secondary OM Title\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), secondary_om_description.lower())):\n",
        "    #     # print(\"found\", \"Secondary OM Description\")\n",
        "    #     variant_found_in.append(f\"{variant} = Secondary OM Description\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), other_om_title.lower())):\n",
        "    #     # print(\"found\", \"Other OM Title\")\n",
        "    #     variant_found_in.append(f\"{variant} = Other OM Title\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), other_om_description.lower())):\n",
        "    #     # print(\"found\", \"Other OM Description\")\n",
        "    #     variant_found_in.append(f\"{variant} = Other OM Description\")\n",
        "    #     variants_found_list.append(variant)\n",
        "    #   if (re.findall(r\"\\b{}\\b\".format(variant), mesh_terms.lower())):\n",
        "    #     # print(\"found\", \"MeSH Terms\")\n",
        "    #     variant_found_in.append(f\"{variant} = MeSH Terms\")\n",
        "    #     variants_found_list.append(variant)\n",
        "\n",
        "    # variant_found_in_string = \" | \".join(variant_found_in)\n",
        "    # variant_found_in_list = variant_found_in_string.split(\" | \")\n",
        "\n",
        "    # variants_found_list = list(set(variants_found_list))\n",
        "    # variants_found_string = \" | \".join(variants_found_list)\n",
        "\n",
        "\n",
        "    # print(\"Variant found in completed\")\n",
        "\n",
        "    # -------------------------------------- For assigning rank for the nct id --------------------------------------------\n",
        "\n",
        "    rank = \"\"\n",
        "\n",
        "    final_check_list = []\n",
        "    if \"\" not in gene_found_in_list:\n",
        "      # print(gene_found_in_list)\n",
        "      for gene_value in gene_found_in_list:\n",
        "        check_data = gene_value.split(\" = \")[1]\n",
        "        final_check_list.append(check_data)\n",
        "\n",
        "      for column_value in final_check_list:\n",
        "\n",
        "        if \"Inclusion Criteria\" in final_check_list or \"Official Title\" in final_check_list or \"Cancer Type\" in final_check_list or \"Arm Title\" in final_check_list or \"Arm Description\" in final_check_list or \"Brief Title\" in final_check_list or \"Intervention Description\" in final_check_list:\n",
        "          rank = \"1A\"\n",
        "        elif \"Brief Summary\" in final_check_list or \"Detailed Description\" in final_check_list or \"Keywords\" in final_check_list:\n",
        "          rank = \"1B\"\n",
        "        elif \"Exclusion Criteria\" in final_check_list:\n",
        "          rank = \"3\"\n",
        "        elif \"Eligibility Criteria\" in final_check_list:\n",
        "          rank = \"1C\"\n",
        "        elif \"Primary OM Title\" in final_check_list or \"Primary OM Description\" in final_check_list or \"Secondary OM Title\" in final_check_list or \"Secondary OM Description\" in final_check_list or \"Other OM Title\" in final_check_list or \"Other OM Description\" in final_check_list or \"MeSH Terms\" in final_check_list:\n",
        "          rank = \"2\"\n",
        "    # -------------------------------------- For assigning rank for the nct id --------------------------------------------\n",
        "\n",
        "    # ---------------------------------------For assiging drugs and pathway --------------------------------------------------------\n",
        "    \n",
        "    # drug_check_list = []\n",
        "    # drug_not_found_list = []\n",
        "    # pathway_found_list = []\n",
        "\n",
        "    # if \"||\" in intervention:\n",
        "    #   drug_list = intervention.split(\"||\")\n",
        "    #   for drug in drug_list:\n",
        "    #     drug = drug.strip()\n",
        "    #     if drug.title() in target_pathway_df['DrugName'].values or drug.lower() in target_pathway_df['DrugName'].values or drug.upper() in target_pathway_df['DrugName'].values:\n",
        "    #       result = target_pathway_df.loc[(target_pathway_df['DrugName'].str.lower() == drug.lower())]\n",
        "    #       drug_match = result['Target'].to_string(index=False).strip()\n",
        "    #       pathway_match = result['Pathway'].to_string(index=False).strip()\n",
        "    #       drug_check_list.append(f\"{drug} = {drug_match}\")\n",
        "    #       pathway_found_list.append(f\"{4/1AX4XfWhVSjrkAeRzFOloPa-ofd141lniTyYBlRlHyn4crNVhJKtS2CtHICEdrug} = {pathway_match}\")\n",
        "    #     else:\n",
        "    #       drug_not_found_list.append(drug)\n",
        "    # elif \"and\" in intervention:\n",
        "    #   drug_list = intervention.split(\"and\")\n",
        "    #   for drug in drug_list:\n",
        "    #     drug = drug.strip()\n",
        "    #     # print(\"2 executed\")\n",
        "    #     if drug.title() in target_pathway_df['DrugName'].values or drug.lower() in target_pathway_df['DrugName'].values or drug.upper() in target_pathway_df['DrugName'].values:\n",
        "    #       # print(\"found2\")\n",
        "    #       result = target_pathway_df.loc[(target_pathway_df['DrugName'].str.lower() == drug.lower())]\n",
        "    #       drug_match = result['Target'].to_string(index=False).strip()\n",
        "    #       pathway_match = result['Pathway'].to_string(index=False).strip()\n",
        "    #       drug_check_list.append(f\"{drug} = {drug_match}\")\n",
        "    #       pathway_found_list.append(f\"{drug} = {pathway_match}\")\n",
        "    #     else:\n",
        "    #       drug_not_found_list.append(drug)\n",
        "    # else:\n",
        "    #   drug = intervention.strip()\n",
        "    #   if drug.title() in target_pathway_df['DrugName'].values or dEGFR - completed in 14.0 minutes rug.lower() in target_pathway_df['DrugName'].values or drug.upper() in target_pathway_df['DrugName'].values:\n",
        "    #     # print(\"found2\")\n",
        "    #     result = target_pathway_df.loc[(target_pathway_df['DrugName'].str.lower() == drug.lower())]\n",
        "    #     drug_match = result['Target'].to_string(index=False).strip()\n",
        "    #     drug_check_list.append(f\"{drug} = {drug_match}\")\n",
        "    #   else:\n",
        "    #     drug_not_found_list.append(drug)'Cancer Type' 'Intervention\n",
        "\n",
        "\n",
        "    # drug_check_string = \" ; \".join(drug_check_list)\n",
        "    # pathway_found_string = \" ; \".join(pathway_found_list)\n",
        "    # drug_not_found_string = \" | \".join(drug_not_found_list)\n",
        "    # #  -----------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "        \n",
        "    trial_rows.append(nct_id)\n",
        "    trial_rows.append(study_type)\n",
        "    trial_rows.append(study_purpose)\n",
        "    trial_rows.append(study_model)\n",
        "    trial_rows.append(overall_status)\n",
        "    trial_rows.append(phase)\n",
        "    trial_rows.append(rank)\n",
        "    trial_rows.append(gene_found_in_string)\n",
        "    trial_rows.append(genes_found_string)\n",
        "    # trial_rows.append(variant_found_in_string)\n",
        "    # trial_rows.append(variants_found_string)\n",
        "    trial_rows.append(brief_title)\n",
        "    trial_rows.append(official_title)\n",
        "    trial_rows.append(brief_summary)\n",
        "    trial_rows.append(detailed_description)\n",
        "    trial_rows.append(cancer_type)\n",
        "    trial_rows.append(intervention)\n",
        "    trial_rows.append(intervention_description)\n",
        "    trial_rows.append(intervention_other_name)\n",
        "    trial_rows.append(arm_title)\n",
        "    trial_rows.append(arm_description)\n",
        "    trial_rows.append(arm_group_intervention)\n",
        "    trial_rows.append(eligibility_criteria)\n",
        "    trial_rows.append(inclusion_criteria)\n",
        "    trial_rows.append(exclusion_criteria)\n",
        "    trial_rows.append(character_count)\n",
        "    trial_rows.append(primary_om_title)\n",
        "    trial_rows.append(primary_om_description)\n",
        "    trial_rows.append(secondary_om_title)\n",
        "    trial_rows.append(secondary_om_description)\n",
        "    trial_rows.append(other_om_title)\n",
        "    trial_rows.append(other_om_description)\n",
        "    trial_rows.append(keywords)\n",
        "    trial_rows.append(mesh_terms)\n",
        "    trial_rows.append(pmid)\n",
        "    trial_rows.append(url)\n",
        "    \n",
        "    # trial_rows.append(variant_found_in_string)\n",
        "    # trial_rows.append(drug_check_string)\n",
        "    # trial_rows.append(pathway_found_string)\n",
        "    # trial_rows.append(drug_not_found_string)\n",
        "    \n",
        "    result_list.append(trial_rows)\n",
        "\n",
        "  # result_list_df = pd.DataFrame(result_list, columns = [\"NCT ID\", \"Study Type\", \"Recruitment Status\", \"Phase\", \"Brief Title\", \"Official Title\", \"Brief Summary\", \"Detailed Description\", \"Cancer Type\", \"Study Purpose\", \"Intervention\", \"Intervention Description\", \"Intervention Other Name\", \"Study Model\", \"Arm Title\", \"Arm Description\", \"Arm Group Intervention\", \"Eligibility Criteria\", \"Inclusion Criteria\", \"Exclusion Criteria\", \"Keywords\", \"PMID\", \"URL\", \"Primary OM Title\", \"Primary OM Description\", \"Secondary OM Title\", \"Secondary OM Description\", \"Other OM Title\", \"Other OM Description\", \"MeSH Terms\", \"Character Count\", \"Gene Found In\", \"Rank\", \"Drug Match\", \"Pathway Match\", \"Drug Not Found\"])\n",
        "  result_list_df = pd.DataFrame(result_list, columns = ['NCT ID', 'Study Type', 'Study Purpose', 'Study Model', 'Recruitment Status', 'Phase', 'Level', 'Gene Found In', 'Gene Aliases Found', 'Brief Title', 'Official Title', 'Brief Summary', 'Detailed Description', 'Cancer Type', 'Intervention', 'Intervention Description', 'Intervention Other Name', 'Arm Title', 'Arm Description', 'Arm Group Intervention', 'Eligibility Criteria', 'Inclusion Criteria', 'Exclusion Criteria', 'Character Count', 'Primary OM Title', 'Primary OM Description', 'Secondary OM Title', 'Secondary OM Description', 'Other OM Title', 'Other OM Description', 'Keywords', 'MeSH Terms', 'PMID', 'URL'])\n",
        "  result_list_df = result_list_df[result_list_df['Gene Found In'] != \"\"]\n",
        "  return result_list_df\n",
        "    "
      ],
      "metadata": {
        "id": "KMA6Hr5idhin"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variant_exact_match(sheet_df, gene):\n",
        "  #get Variant Names\n",
        "  variant_sh = gc.open_by_key(\"1_hKejRNMKYEf4jPQYSvzJZZUHIm-eNDDcuyc8LB6L5M\")\n",
        "  variant_sheet = variant_sh.worksheet('DummyData')\n",
        "  variant_rows = variant_sheet.get_all_values()\n",
        "\n",
        "  #converting to dataframe\n",
        "  variant_df = pd.DataFrame(variant_rows[1:], columns=variant_rows[0])\n",
        "\n",
        "  # drop rows which is having none and unknown\n",
        "  variant_df = variant_df[variant_df['Impact'] != \"none\"]\n",
        "  variant_df = variant_df[variant_df['Impact'] != \"unknown\"]\n",
        "\n",
        "  data = variant_df.loc[(variant_df.Gene == gene)]\n",
        "  variant_names = data['Variant'].to_numpy().tolist()\n",
        "  \n",
        "  result_list = [] \n",
        "  for index in sheet_df.index: # nct = 1, 2\n",
        "  \n",
        "    \n",
        "    # variant_found_in = []\n",
        "    # variants_found_list = []\n",
        "\n",
        "    data_df = sheet_df.loc[index]\n",
        "  \n",
        "    \n",
        "    nct_id = data_df['NCT ID']\n",
        "    study_type = data_df['Study Type']\n",
        "    overall_status = data_df['Recruitment Status']\n",
        "    phase = data_df['Phase']\n",
        "    brief_title = data_df['Brief Title']\n",
        "    official_title = data_df['Official Title']\n",
        "    brief_summary = data_df['Brief Summary']\n",
        "    detailed_description = data_df['Detailed Description']\n",
        "    cancer_type = data_df['Cancer Type']\n",
        "    study_purpose = data_df['Study Purpose']\n",
        "    intervention = data_df['Intervention']\n",
        "    intervention_description = data_df['Intervention Description']\n",
        "    intervention_other_name = data_df['Intervention Other Name']\n",
        "    study_model = data_df['Study Model']\n",
        "    arm_title = data_df['Arm Title']\n",
        "    arm_description = data_df['Arm Description']\n",
        "    arm_group_intervention = data_df['Arm Group Intervention']\n",
        "    eligibility_criteria = data_df['Eligibility Criteria']\n",
        "    inclusion_criteria = data_df['Inclusion Criteria']\n",
        "    exclusion_criteria = data_df['Exclusion Criteria']\n",
        "    keywords = data_df['Keywords']\n",
        "    pmid = data_df['PMID']\n",
        "    url = data_df['URL']\n",
        "    primary_om_title = data_df['Primary OM Title']\n",
        "    primary_om_description = data_df['Primary OM Description']\n",
        "    secondary_om_title = data_df['Secondary OM Title']\n",
        "    secondary_om_description = data_df['Secondary OM Description']\n",
        "    other_om_title = data_df['Other OM Title']\n",
        "    other_om_description = data_df['Other OM Description']\n",
        "    mesh_terms = data_df['MeSH Terms']\n",
        "    character_count = data_df['Character Count']\n",
        "    gene_found_in = data_df['Gene Found In']\n",
        "    gene_aliases_found = data_df['Gene Aliases Found']\n",
        "    rank = data_df['Level']\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for variant in variant_names: #a, b\n",
        "      variant = variant.lower()\n",
        "      trial_rows=[]\n",
        "      variant_found_in = []\n",
        "      variants_found_list = []\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), brief_title.lower())):\n",
        "        # print(\"found\", \"Brief Title\")\n",
        "        variant_found_in.append(f\"{variant} = Brief Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), official_title.lower())):\n",
        "        # print(\"found\", \"Official Title\")\n",
        "        variant_found_in.append(f\"{variant} = Official Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), brief_summary.lower())):\n",
        "        # print(\"found\", \"Brief Summary\")\n",
        "        variant_found_in.append(f\"{variant} = Brief Summary\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), detailed_description.lower())):\n",
        "        # print(\"found\", \"Detailed Description\")\n",
        "        variant_found_in.append(f\"{variant} = Detailed Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), cancer_type.lower())):\n",
        "        # print(\"found\", \"Cancer Type\")\n",
        "        variant_found_in.append(f\"{variant} = Cancer Type\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), intervention_description.lower())):\n",
        "        # print(\"found\", \"Intervention Description\")\n",
        "        variant_found_in.append(f\"{variant} = Intervention Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), arm_title.lower())):\n",
        "        # print(\"found\", \"Arm Title\")\n",
        "        variant_found_in.append(f\"{variant} = Arm Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), arm_description.lower())):\n",
        "        # print(\"found\", \"Arm Description\")\n",
        "        variant_found_in.append(f\"{variant} = Arm Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), eligibility_criteria.lower())):\n",
        "        # print(\"found\", \"Eligibility Criterial\")\n",
        "        variant_found_in.append(f\"{variant} = Eligibility Criteria\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), inclusion_criteria.lower())):\n",
        "        # print(\"found\", \"Inclusion Criteria\")\n",
        "        variant_found_in.append(f\"{variant} = Inclusion Criteria\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), exclusion_criteria.lower())):\n",
        "        # print(\"found\", \"Exclusion Criteria\")\n",
        "        variant_found_in.append(f\"{variant} = Exclusion Criteria\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), keywords.lower())):\n",
        "        # print(\"found\", \"Keywords\")\n",
        "        variant_found_in.append(f\"{variant} = Keywords\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), primary_om_title.lower())):\n",
        "        # print(\"found\", \"Primary OM Title\")\n",
        "        variant_found_in.append(f\"{variant} = Primary OM Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), primary_om_description.lower())):\n",
        "        # print(\"found\", \"Primary OM Description\")\n",
        "        variant_found_in.append(f\"{variant} = Primary OM Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), secondary_om_title.lower())):\n",
        "        # print(\"found\", \"Secondary OM Title\")\n",
        "        variant_found_in.append(f\"{variant} = Secondary OM Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), secondary_om_description.lower())):\n",
        "        # print(\"found\", \"Secondary OM Description\")\n",
        "        variant_found_in.append(f\"{variant} = Secondary OM Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), other_om_title.lower())):\n",
        "        # print(\"found\", \"Other OM Title\")\n",
        "        variant_found_in.append(f\"{variant} = Other OM Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), other_om_description.lower())):\n",
        "        # print(\"found\", \"Other OM Description\")\n",
        "        variant_found_in.append(f\"{variant} = Other OM Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(variant), mesh_terms.lower())):\n",
        "        # print(\"found\", \"MeSH Terms\")\n",
        "        variant_found_in.append(f\"{variant} = MeSH Terms\")\n",
        "        variants_found_list.append(variant)\n",
        "\n",
        "      variant_found_in_string = \" | \".join(variant_found_in)\n",
        "      variant_found_in_list = variant_found_in_string.split(\" | \")\n",
        "\n",
        "      variants_found_list = list(set(variants_found_list))\n",
        "      variants_found_string = \" | \".join(variants_found_list)\n",
        "\n",
        "      if len(variants_found_list) != 0:\n",
        "      \n",
        "        trial_rows.append(nct_id)\n",
        "        trial_rows.append(study_type)\n",
        "        trial_rows.append(study_purpose)\n",
        "        trial_rows.append(study_model)\n",
        "        trial_rows.append(overall_status)\n",
        "        trial_rows.append(phase)\n",
        "        trial_rows.append(rank)\n",
        "        trial_rows.append(gene_found_in)\n",
        "        trial_rows.append(gene_aliases_found)\n",
        "        trial_rows.append(variant_found_in_string)\n",
        "        trial_rows.append(variants_found_string)\n",
        "        trial_rows.append(\"Exact Match\")\n",
        "        trial_rows.append(brief_title)\n",
        "        trial_rows.append(official_title)\n",
        "        trial_rows.append(brief_summary)\n",
        "        trial_rows.append(detailed_description)\n",
        "        trial_rows.append(cancer_type)\n",
        "        trial_rows.append(intervention)\n",
        "        trial_rows.append(intervention_description)\n",
        "        trial_rows.append(intervention_other_name)\n",
        "        trial_rows.append(arm_title)\n",
        "        trial_rows.append(arm_description)\n",
        "        trial_rows.append(arm_group_intervention)\n",
        "        trial_rows.append(eligibility_criteria)\n",
        "        trial_rows.append(inclusion_criteria)\n",
        "        trial_rows.append(exclusion_criteria)\n",
        "        trial_rows.append(character_count)\n",
        "        trial_rows.append(primary_om_title)\n",
        "        trial_rows.append(primary_om_description)\n",
        "        trial_rows.append(secondary_om_title)\n",
        "        trial_rows.append(secondary_om_description)\n",
        "        trial_rows.append(other_om_title)\n",
        "        trial_rows.append(other_om_description)\n",
        "        trial_rows.append(keywords)\n",
        "        trial_rows.append(mesh_terms)\n",
        "        trial_rows.append(pmid)\n",
        "        trial_rows.append(url)\n",
        "        result_list.append(trial_rows)\n",
        "\n",
        "        count = count + 1\n",
        "    \n",
        "    if count == 0:\n",
        "\n",
        "      trial_rows.append(nct_id)\n",
        "      trial_rows.append(study_type)\n",
        "      trial_rows.append(study_purpose)\n",
        "      trial_rows.append(study_model)\n",
        "      trial_rows.append(overall_status)\n",
        "      trial_rows.append(phase)\n",
        "      trial_rows.append(rank)\n",
        "      trial_rows.append(gene_found_in)\n",
        "      trial_rows.append(gene_aliases_found)\n",
        "      trial_rows.append(variant_found_in_string)\n",
        "      trial_rows.append(variants_found_string)\n",
        "      trial_rows.append(\"VNF\")\n",
        "      trial_rows.append(brief_title)\n",
        "      trial_rows.append(official_title)\n",
        "      trial_rows.append(brief_summary)\n",
        "      trial_rows.append(detailed_description)\n",
        "      trial_rows.append(cancer_type)\n",
        "      trial_rows.append(intervention)\n",
        "      trial_rows.append(intervention_description)\n",
        "      trial_rows.append(intervention_other_name)\n",
        "      trial_rows.append(arm_title)\n",
        "      trial_rows.append(arm_description)\n",
        "      trial_rows.append(arm_group_intervention)\n",
        "      trial_rows.append(eligibility_criteria)\n",
        "      trial_rows.append(inclusion_criteria)\n",
        "      trial_rows.append(exclusion_criteria)\n",
        "      trial_rows.append(character_count)\n",
        "      trial_rows.append(primary_om_title)\n",
        "      trial_rows.append(primary_om_description)\n",
        "      trial_rows.append(secondary_om_title)\n",
        "      trial_rows.append(secondary_om_description)\n",
        "      trial_rows.append(other_om_title)\n",
        "      trial_rows.append(other_om_description)\n",
        "      trial_rows.append(keywords)\n",
        "      trial_rows.append(mesh_terms)\n",
        "      trial_rows.append(pmid)\n",
        "      trial_rows.append(url)\n",
        "      result_list.append(trial_rows)\n",
        "\n",
        "  \n",
        "    \n",
        "        \n",
        "    # trial_rows.append(variant_found_in_string)\n",
        "    # trial_rows.append(drug_check_string)\n",
        "    # trial_rows.append(pathway_found_string)\n",
        "    # trial_rows.append(drug_not_found_string)\n",
        "    \n",
        "    # result_list.append(trial_rowsresult_list.append(trial_rows))\n",
        "\n",
        "  # result_list_df = pd.DataFrame(result_list, columns = [\"NCT ID\", \"Study Type\", \"Recruitment Status\", \"Phase\", \"Brief Title\", \"Official Title\", \"Brief Summary\", \"Detailed Description\", \"Cancer Type\", \"Study Purpose\", \"Intervention\", \"Intervention Description\", \"Intervention Other Name\", \"Study Model\", \"Arm Title\", \"Arm Description\", \"Arm Group Intervention\", \"Eligibility Criteria\", \"Inclusion Criteria\", \"Exclusion Criteria\", \"Keywords\", \"PMID\", \"URL\", \"Primary OM Title\", \"Primary OM Description\", \"Secondary OM Title\", \"Secondary OM Description\", \"Other OM Title\", \"Other OM Description\", \"MeSH Terms\", \"Character Count\", \"Gene Found In\", \"Rank\", \"Drug Match\", \"Pathway Match\", \"Drug Not Found\"])\n",
        "  result_list_df = pd.DataFrame(result_list, columns = ['NCT ID', 'Study Type', 'Study Purpose', 'Study Model', 'Recruitment Status', 'Phase', 'Level', 'Gene Found In', 'Gene Aliases Found', 'Variant Found In', 'Variants Found', 'Variant Match Type', 'Brief Title', 'Official Title', 'Brief Summary', 'Detailed Description', 'Cancer Type', 'Intervention', 'Intervention Description', 'Intervention Other Name', 'Arm Title', 'Arm Description', 'Arm Group Intervention', 'Eligibility Criteria', 'Inclusion Criteria', 'Exclusion Criteria', 'Character Count', 'Primary OM Title', 'Primary OM Description', 'Secondary OM Title', 'Secondary OM Description', 'Other OM Title', 'Other OM Description', 'Keywords', 'MeSH Terms', 'PMID', 'URL'])\n",
        "  # result_list_df = result_list_df[result_list_df['Gene Found In'] != \"\"]\n",
        "  return result_list_df\n",
        "    \n"
      ],
      "metadata": {
        "id": "HKOoEHcl09w-"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def missense_codon_match(sheet_df, gene):\n",
        "  #get Variant Names\n",
        "  variant_sh = gc.open_by_key(\"1_hKejRNMKYEf4jPQYSvzJZZUHIm-eNDDcuyc8LB6L5M\")\n",
        "  variant_sheet = variant_sh.worksheet('DummyData')\n",
        "  variant_rows = variant_sheet.get_all_values()\n",
        "\n",
        "  variant_df = pd.DataFrame(variant_rows[1:], columns=variant_rows[0])\n",
        "\n",
        "  variant_df = variant_df[variant_df['Impact'] == \"missense\"]\n",
        "\n",
        "  data = variant_df.loc[(variant_df.Gene == gene)]\n",
        "\n",
        "\n",
        "  variants = data['Variant'].to_numpy().tolist()\n",
        "  codons = data['Codon'].to_numpy().tolist()\n",
        "\n",
        "  i = 0\n",
        "  variant_names = []\n",
        "  for i in range(len(variants)):\n",
        "    variant = f\"{variants[i]}|{codons[i]}\"\n",
        "    variant_names.append(variant)\n",
        "  \n",
        "  result_list = [] \n",
        "  for index in sheet_df.index: # nct = 1, 2\n",
        "\n",
        "    data_df = sheet_df.loc[index]\n",
        "  \n",
        "    nct_id = data_df['NCT ID']\n",
        "    study_type = data_df['Study Type']\n",
        "    overall_status = data_df['Recruitment Status']\n",
        "    phase = data_df['Phase']\n",
        "    brief_title = data_df['Brief Title'].lower()\n",
        "    official_title = data_df['Official Title'].lower()\n",
        "    brief_summary = data_df['Brief Summary'].lower()\n",
        "    detailed_description = data_df['Detailed Description'].lower()\n",
        "    cancer_type = data_df['Cancer Type'].lower()\n",
        "    study_purpose = data_df['Study Purpose']\n",
        "    intervention = data_df['Intervention']\n",
        "    intervention_description = data_df['Intervention Description'].lower()\n",
        "    intervention_other_name = data_df['Intervention Other Name']\n",
        "    study_model = data_df['Study Model']\n",
        "    arm_title = data_df['Arm Title'].lower()\n",
        "    arm_description = data_df['Arm Description'].lower()\n",
        "    arm_group_intervention = data_df['Arm Group Intervention']\n",
        "    eligibility_criteria = data_df['Eligibility Criteria'].lower()\n",
        "    inclusion_criteria = data_df['Inclusion Criteria'].lower()\n",
        "    exclusion_criteria = data_df['Exclusion Criteria'].lower()\n",
        "    keywords = data_df['Keywords'].lower()\n",
        "    pmid = data_df['PMID']\n",
        "    url = data_df['URL']\n",
        "    primary_om_title = data_df['Primary OM Title'].lower()\n",
        "    primary_om_description = data_df['Primary OM Description'].lower()\n",
        "    secondary_om_title = data_df['Secondary OM Title'].lower()\n",
        "    secondary_om_description = data_df['Secondary OM Description'].lower()\n",
        "    other_om_title = data_df['Other OM Title'].lower()\n",
        "    other_om_description = data_df['Other OM Description'].lower()\n",
        "    mesh_terms = data_df['MeSH Terms'].lower()\n",
        "    character_count = data_df['Character Count']\n",
        "    gene_found_in = data_df['Gene Found In']\n",
        "    gene_aliases_found = data_df['Gene Aliases Found']\n",
        "    rank = data_df['Level']\n",
        "\n",
        "    brief_title = brief_title.replace(\"codons\", \"codon\")\n",
        "    official_title = official_title.replace(\"codons\", \"codon\")\n",
        "    brief_summary = brief_summary.replace(\"codons\", \"codon\")\n",
        "    detailed_description = detailed_description.replace(\"codons\", \"codon\")\n",
        "    cancer_type = cancer_type.replace(\"codons\", \"codon\")\n",
        "    intervention_description = intervention_description.replace(\"codons\", \"codon\")\n",
        "    arm_title = arm_title.replace(\"codons\", \"codon\")\n",
        "    arm_description = arm_description.replace(\"codons\", \"codon\")\n",
        "    eligibility_criteria = eligibility_criteria.replace(\"codons\", \"codon\")\n",
        "    inclusion_criteria = inclusion_criteria.replace(\"codons\", \"codon\")\n",
        "    exclusion_criteria = exclusion_criteria.replace(\"codons\", \"codon\")\n",
        "    keywords = keywords.replace(\"codons\", \"codon\")\n",
        "    primary_om_title = primary_om_title.replace(\"codons\", \"codon\")\n",
        "    primary_om_description = primary_om_description.replace(\"codons\", \"codon\")\n",
        "    secondary_om_title = secondary_om_title.replace(\"codons\", \"codon\")\n",
        "    secondary_om_description = secondary_om_description.replace(\"codons\", \"codon\")\n",
        "    other_om_title = other_om_title.replace(\"codons\", \"codon\")\n",
        "    other_om_description = other_om_description.replace(\"codons\", \"codon\")\n",
        "    mesh_terms = mesh_terms.replace(\"codons\", \"codon\")\n",
        "\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for variant in variant_names: #a, b\n",
        "      variant, codon = variant.split(\"|\")\n",
        "      codon = f\"codon {codon}\"\n",
        "      codon = codon.lower()\n",
        "      trial_rows=[]\n",
        "      variant_found_in = []\n",
        "      variants_found_list = []\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), brief_title.lower())):\n",
        "        # print(\"found\", \"Brief Title\")\n",
        "        variant_found_in.append(f\"{codon} = Brief Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), official_title.lower())):\n",
        "        # print(\"found\", \"Official Title\")\n",
        "        variant_found_in.append(f\"{codon} = Official Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), brief_summary.lower())):\n",
        "        # print(\"found\", \"Brief Summary\")\n",
        "        variant_found_in.append(f\"{codon} = Brief Summary\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), detailed_description.lower())):\n",
        "        # print(\"found\", \"Detailed Description\")\n",
        "        variant_found_in.append(f\"{codon} = Detailed Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), cancer_type.lower())):\n",
        "        # print(\"found\", \"Cancer Type\")\n",
        "        variant_found_in.append(f\"{codon} = Cancer Type\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), intervention_description.lower())):\n",
        "        # print(\"found\", \"Intervention Description\")\n",
        "        variant_found_in.append(f\"{codon} = Intervention Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), arm_title.lower())):\n",
        "        # print(\"found\", \"Arm Title\")\n",
        "        variant_found_in.append(f\"{codon} = Arm Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), arm_description.lower())):\n",
        "        # print(\"found\", \"Arm Description\")\n",
        "        variant_found_in.append(f\"{codon} = Arm Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), eligibility_criteria.lower())):\n",
        "        # print(\"found\", \"Eligibility Criterial\")\n",
        "        variant_found_in.append(f\"{codon} = Eligibility Criteria\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), inclusion_criteria.lower())):\n",
        "        # print(\"found\", \"Inclusion Criteria\")\n",
        "        variant_found_in.append(f\"{codon} = Inclusion Criteria\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), exclusion_criteria.lower())):\n",
        "        # print(\"found\", \"Exclusion Criteria\")\n",
        "        variant_found_in.append(f\"{codon} = Exclusion Criteria\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), keywords.lower())):\n",
        "        # print(\"found\", \"Keywords\")\n",
        "        variant_found_in.append(f\"{codon} = Keywords\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), primary_om_title.lower())):\n",
        "        # print(\"found\", \"Primary OM Title\")\n",
        "        variant_found_in.append(f\"{codon} = Primary OM Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), primary_om_description.lower())):\n",
        "        # print(\"found\", \"Primary OM Description\")\n",
        "        variant_found_in.append(f\"{codon} = Primary OM Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), secondary_om_title.lower())):\n",
        "        # print(\"found\", \"Secondary OM Title\")\n",
        "        variant_found_in.append(f\"{codon} = Secondary OM Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), secondary_om_description.lower())):\n",
        "        # print(\"found\", \"Secondary OM Description\")\n",
        "        variant_found_in.append(f\"{codon} = Secondary OM Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), other_om_title.lower())):\n",
        "        # print(\"found\", \"Other OM Title\")\n",
        "        variant_found_in.append(f\"{codon} = Other OM Title\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), other_om_description.lower())):\n",
        "        # print(\"found\", \"Other OM Description\")\n",
        "        variant_found_in.append(f\"{codon} = Other OM Description\")\n",
        "        variants_found_list.append(variant)\n",
        "      if (re.findall(r\"\\b{}\\b\".format(codon), mesh_terms.lower())):\n",
        "        # print(\"found\", \"MeSH Terms\")\n",
        "        variant_found_in.append(f\"{codon} = MeSH Terms\")\n",
        "        variants_found_list.append(variant)\n",
        "\n",
        "      variant_found_in_string = \" | \".join(variant_found_in)\n",
        "      variant_found_in_list = variant_found_in_string.split(\" | \")\n",
        "\n",
        "      variants_found_list = list(set(variants_found_list))\n",
        "      variants_found_string = \" | \".join(variants_found_list)\n",
        "\n",
        "      if len(variants_found_list) != 0:\n",
        "      \n",
        "        trial_rows.append(nct_id)\n",
        "        trial_rows.append(study_type)\n",
        "        trial_rows.append(study_purpose)\n",
        "        trial_rows.append(study_model)\n",
        "        trial_rows.append(overall_status)\n",
        "        trial_rows.append(phase)\n",
        "        trial_rows.append(rank)\n",
        "        trial_rows.append(gene_found_in)\n",
        "        trial_rows.append(gene_aliases_found)\n",
        "        trial_rows.append(variant_found_in_string)\n",
        "        trial_rows.append(variants_found_string)\n",
        "        trial_rows.append(\"Codon Match\")\n",
        "        trial_rows.append(brief_title)\n",
        "        trial_rows.append(official_title)\n",
        "        trial_rows.append(brief_summary)\n",
        "        trial_rows.append(detailed_description)\n",
        "        trial_rows.append(cancer_type)\n",
        "        trial_rows.append(intervention)\n",
        "        trial_rows.append(intervention_description)\n",
        "        trial_rows.append(intervention_other_name)\n",
        "        trial_rows.append(arm_title)\n",
        "        trial_rows.append(arm_description)\n",
        "        trial_rows.append(arm_group_intervention)\n",
        "        trial_rows.append(eligibility_criteria)\n",
        "        trial_rows.append(inclusion_criteria)\n",
        "        trial_rows.append(exclusion_criteria)\n",
        "        trial_rows.append(character_count)\n",
        "        trial_rows.append(primary_om_title)\n",
        "        trial_rows.append(primary_om_description)\n",
        "        trial_rows.append(secondary_om_title)\n",
        "        trial_rows.append(secondary_om_description)\n",
        "        trial_rows.append(other_om_title)\n",
        "        trial_rows.append(other_om_description)\n",
        "        trial_rows.append(keywords)\n",
        "        trial_rows.append(mesh_terms)\n",
        "        trial_rows.append(pmid)\n",
        "        trial_rows.append(url)\n",
        "        result_list.append(trial_rows)\n",
        "\n",
        "        count = count + 1\n",
        "    \n",
        "    if count == 0:\n",
        "\n",
        "      trial_rows.append(nct_id)\n",
        "      trial_rows.append(study_type)\n",
        "      trial_rows.append(study_purpose)\n",
        "      trial_rows.append(study_model)\n",
        "      trial_rows.append(overall_status)\n",
        "      trial_rows.append(phase)\n",
        "      trial_rows.append(rank)\n",
        "      trial_rows.append(gene_found_in)\n",
        "      trial_rows.append(gene_aliases_found)\n",
        "      trial_rows.append(variant_found_in_string)\n",
        "      trial_rows.append(variants_found_string)\n",
        "      trial_rows.append(\"VNF\")\n",
        "      trial_rows.append(brief_title)\n",
        "      trial_rows.append(official_title)\n",
        "      trial_rows.append(brief_summary)\n",
        "      trial_rows.append(detailed_description)\n",
        "      trial_rows.append(cancer_type)\n",
        "      trial_rows.append(intervention)\n",
        "      trial_rows.append(intervention_description)\n",
        "      trial_rows.append(intervention_other_name)\n",
        "      trial_rows.append(arm_title)\n",
        "      trial_rows.append(arm_description)\n",
        "      trial_rows.append(arm_group_intervention)\n",
        "      trial_rows.append(eligibility_criteria)\n",
        "      trial_rows.append(inclusion_criteria)\n",
        "      trial_rows.append(exclusion_criteria)\n",
        "      trial_rows.append(character_count)\n",
        "      trial_rows.append(primary_om_title)\n",
        "      trial_rows.append(primary_om_description)\n",
        "      trial_rows.append(secondary_om_title)\n",
        "      trial_rows.append(secondary_om_description)\n",
        "      trial_rows.append(other_om_title)\n",
        "      trial_rows.append(other_om_description)\n",
        "      trial_rows.append(keywords)\n",
        "      trial_rows.append(mesh_terms)\n",
        "      trial_rows.append(pmid)\n",
        "      trial_rows.append(url)\n",
        "      result_list.append(trial_rows)\n",
        "      \n",
        "    # trial_rows.append(variant_found_in_string)\n",
        "    # trial_rows.append(drug_check_string)\n",
        "    # trial_rows.append(pathway_found_string)\n",
        "    # trial_rows.append(drug_not_found_string)\n",
        "    \n",
        "    # result_list.append(trial_rowsresult_list.append(trial_rows))\n",
        "\n",
        "  # result_list_df = pd.DataFrame(result_list, columns = [\"NCT ID\", \"Study Type\", \"Recruitment Status\", \"Phase\", \"Brief Title\", \"Official Title\", \"Brief Summary\", \"Detailed Description\", \"Cancer Type\", \"Study Purpose\", \"Intervention\", \"Intervention Description\", \"Intervention Other Name\", \"Study Model\", \"Arm Title\", \"Arm Description\", \"Arm Group Intervention\", \"Eligibility Criteria\", \"Inclusion Criteria\", \"Exclusion Criteria\", \"Keywords\", \"PMID\", \"URL\", \"Primary OM Title\", \"Primary OM Description\", \"Secondary OM Title\", \"Secondary OM Description\", \"Other OM Title\", \"Other OM Description\", \"MeSH Terms\", \"Character Count\", \"Gene Found In\", \"Rank\", \"Drug Match\", \"Pathway Match\", \"Drug Not Found\"])\n",
        "  result_list_df = pd.DataFrame(result_list, columns = ['NCT ID', 'Study Type', 'Study Purpose', 'Study Model', 'Recruitment Status', 'Phase', 'Level', 'Gene Found In', 'Gene Aliases Found', 'Variant Found In', 'Variants Found', 'Variant Match Type', 'Brief Title', 'Official Title', 'Brief Summary', 'Detailed Description', 'Cancer Type', 'Intervention', 'Intervention Description', 'Intervention Other Name', 'Arm Title', 'Arm Description', 'Arm Group Intervention', 'Eligibility Criteria', 'Inclusion Criteria', 'Exclusion Criteria', 'Character Count', 'Primary OM Title', 'Primary OM Description', 'Secondary OM Title', 'Secondary OM Description', 'Other OM Title', 'Other OM Description', 'Keywords', 'MeSH Terms', 'PMID', 'URL'])\n",
        "  # result_list_df = result_list_df[result_list_df['Gene Found In'] != \"\"]\n",
        "  return result_list_df\n",
        "    \n"
      ],
      "metadata": {
        "id": "X19NEPegN8BS"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def duplication_codon_match(sheet_df, gene):\n",
        "  variant_sh = gc.open_by_key(\"1_hKejRNMKYEf4jPQYSvzJZZUHIm-eNDDcuyc8LB6L5M\")\n",
        "  variant_sheet = variant_sh.worksheet('DummyData')\n",
        "  variant_rows = variant_sheet.get_all_values()\n",
        "\n",
        "  variant_df = pd.DataFrame(variant_rows[1:], columns=variant_rows[0])\n",
        "\n",
        "  variant_df = variant_df[variant_df['Impact'] == \"duplication\"]  \n",
        "  data = variant_df.loc[(variant_df.Gene == gene)]\n",
        "  variants = data['Variant'].to_numpy().tolist()\n",
        "  \n",
        "  if len(variants) != 0:\n",
        "    variant_names = []\n",
        "    for variant in variants:\n",
        "      if \"_\" in variant:\n",
        "        codon1, codon2 = variant.split(\"dup\")[0].split(\"_\")\n",
        "        codon1 = codon1 + \"dup\"\n",
        "        codon2 = codon2 + \"dup\"\n",
        "        codon1 = codon1.split(\"dup\")[0][1:]\n",
        "        codon2 = codon2.split(\"dup\")[0][1:]\n",
        "        variant_name = f\"{variant}|{codon1}|{codon2}\"\n",
        "        variant_names.append(variant_name)\n",
        "      else:\n",
        "        codon = variant.split(\"dup\")[0][1:]\n",
        "        variant_name = f\"{variant}|{codon}\"\n",
        "        variant_names.append(variant_name)\n",
        "\n",
        "      \n",
        "    result_list = [] \n",
        "    for index in sheet_df.index: # nct = 1, 2\n",
        "\n",
        "      data_df = sheet_df.loc[index]\n",
        "    \n",
        "      nct_id = data_df['NCT ID']\n",
        "      study_type = data_df['Study Type']\n",
        "      overall_status = data_df['Recruitment Status']\n",
        "      phase = data_df['Phase']\n",
        "      brief_title = data_df['Brief Title'].lower()\n",
        "      official_title = data_df['Official Title'].lower()\n",
        "      brief_summary = data_df['Brief Summary'].lower()\n",
        "      detailed_description = data_df['Detailed Description'].lower()\n",
        "      cancer_type = data_df['Cancer Type'].lower()\n",
        "      study_purpose = data_df['Study Purpose']\n",
        "      intervention = data_df['Intervention']\n",
        "      intervention_description = data_df['Intervention Description'].lower()\n",
        "      intervention_other_name = data_df['Intervention Other Name']\n",
        "      study_model = data_df['Study Model']\n",
        "      arm_title = data_df['Arm Title'].lower()\n",
        "      arm_description = data_df['Arm Description'].lower()\n",
        "      arm_group_intervention = data_df['Arm Group Intervention']\n",
        "      eligibility_criteria = data_df['Eligibility Criteria'].lower()\n",
        "      inclusion_criteria = data_df['Inclusion Criteria'].lower()\n",
        "      exclusion_criteria = data_df['Exclusion Criteria'].lower()\n",
        "      keywords = data_df['Keywords'].lower()\n",
        "      pmid = data_df['PMID']\n",
        "      url = data_df['URL']\n",
        "      primary_om_title = data_df['Primary OM Title'].lower()\n",
        "      primary_om_description = data_df['Primary OM Description'].lower()\n",
        "      secondary_om_title = data_df['Secondary OM Title'].lower()\n",
        "      secondary_om_description = data_df['Secondary OM Description'].lower()\n",
        "      other_om_title = data_df['Other OM Title'].lower()\n",
        "      other_om_description = data_df['Other OM Description'].lower()\n",
        "      mesh_terms = data_df['MeSH Terms'].lower()\n",
        "      character_count = data_df['Character Count']\n",
        "      gene_found_in = data_df['Gene Found In']\n",
        "      gene_aliases_found = data_df['Gene Aliases Found']\n",
        "      rank = data_df['Level']\n",
        "\n",
        "      brief_title = brief_title.replace(\"codons\", \"codon\")\n",
        "      official_title = official_title.replace(\"codons\", \"codon\")\n",
        "      brief_summary = brief_summary.replace(\"codons\", \"codon\")\n",
        "      detailed_description = detailed_description.replace(\"codons\", \"codon\")\n",
        "      cancer_type = cancer_type.replace(\"codons\", \"codon\")\n",
        "      intervention_description = intervention_description.replace(\"codons\", \"codon\")\n",
        "      arm_title = arm_title.replace(\"codons\", \"codon\")\n",
        "      arm_description = arm_description.replace(\"codons\", \"codon\")\n",
        "      eligibility_criteria = eligibility_criteria.replace(\"codons\", \"codon\")\n",
        "      inclusion_criteria = inclusion_criteria.replace(\"codons\", \"codon\")\n",
        "      exclusion_criteria = exclusion_criteria.replace(\"codons\", \"codon\")\n",
        "      keywords = keywords.replace(\"codons\", \"codon\")\n",
        "      primary_om_title = primary_om_title.replace(\"codons\", \"codon\")\n",
        "      primary_om_description = primary_om_description.replace(\"codons\", \"codon\")\n",
        "      secondary_om_title = secondary_om_title.replace(\"codons\", \"codon\")\n",
        "      secondary_om_description = secondary_om_description.replace(\"codons\", \"codon\")\n",
        "      other_om_title = other_om_title.replace(\"codons\", \"codon\")\n",
        "      other_om_description = other_om_description.replace(\"codons\", \"codon\")\n",
        "      mesh_terms = mesh_terms.replace(\"codons\", \"codon\")\n",
        "\n",
        "      count = 0\n",
        "\n",
        "      for variant in variant_names: #a, b\n",
        "        if \"_\" in variant:\n",
        "          for codon in variant.split(\"|\")[1:]:\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), brief_title.lower())):\n",
        "              # print(\"found\", \"Brief Title\")\n",
        "              variant_found_in.append(f\"{codon} = Brief Title\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), official_title.lower())):\n",
        "              # print(\"found\", \"Official Title\")\n",
        "              variant_found_in.append(f\"{codon} = Official Title\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), brief_summary.lower())):\n",
        "              # print(\"found\", \"Brief Summary\")\n",
        "              variant_found_in.append(f\"{codon} = Brief Summary\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), detailed_description.lower())):\n",
        "              # print(\"found\", \"Detailed Description\")\n",
        "              variant_found_in.append(f\"{codon} = Detailed Description\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), cancer_type.lower())):\n",
        "              # print(\"found\", \"Cancer Type\")\n",
        "              variant_found_in.append(f\"{codon} = Cancer Type\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), intervention_description.lower())):\n",
        "              # print(\"found\", \"Intervention Description\")\n",
        "              variant_found_in.append(f\"{codon} = Intervention Description\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), arm_title.lower())):\n",
        "              # print(\"found\", \"Arm Title\")\n",
        "              variant_found_in.append(f\"{codon} = Arm Title\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), arm_description.lower())):\n",
        "              # print(\"found\", \"Arm Description\")\n",
        "              variant_found_in.append(f\"{codon} = Arm Description\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), eligibility_criteria.lower())):\n",
        "              # print(\"found\", \"Eligibility Criterial\")\n",
        "              variant_found_in.append(f\"{codon} = Eligibility Criteria\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), inclusion_criteria.lower())):\n",
        "              # print(\"found\", \"Inclusion Criteria\")\n",
        "              variant_found_in.append(f\"{codon} = Inclusion Criteria\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), exclusion_criteria.lower())):\n",
        "              # print(\"found\", \"Exclusion Criteria\")\n",
        "              variant_found_in.append(f\"{codon} = Exclusion Criteria\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), keywords.lower())):\n",
        "              # print(\"found\", \"Keywords\")\n",
        "              variant_found_in.append(f\"{codon} = Keywords\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), primary_om_title.lower())):\n",
        "              # print(\"found\", \"Primary OM Title\")\n",
        "              variant_found_in.append(f\"{codon} = Primary OM Title\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), primary_om_description.lower())):\n",
        "              # print(\"found\", \"Primary OM Description\")\n",
        "              variant_found_in.append(f\"{codon} = Primary OM Description\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), secondary_om_title.lower())):\n",
        "              # print(\"found\", \"Secondary OM Title\")\n",
        "              variant_found_in.append(f\"{codon} = Secondary OM Title\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), secondary_om_description.lower())):\n",
        "              # print(\"found\", \"Secondary OM Description\")\n",
        "              variant_found_in.append(f\"{codon} = Secondary OM Description\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), other_om_title.lower())):\n",
        "              # print(\"found\", \"Other OM Title\")\n",
        "              variant_found_in.append(f\"{codon} = Other OM Title\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), other_om_description.lower())):\n",
        "              # print(\"found\", \"Other OM Description\")\n",
        "              variant_found_in.append(f\"{codon} = Other OM Description\")\n",
        "              variants_found_list.append(variant)\n",
        "            if (re.findall(r\"\\b{}\\b\".format(codon), mesh_terms.lower())):\n",
        "              # print(\"found\", \"MeSH Terms\")\n",
        "              variant_found_in.append(f\"{codon} = MeSH Terms\")\n",
        "              variants_found_list.append(variant)\n",
        "\n",
        "            variant_found_in_string = \" | \".join(variant_found_in)\n",
        "            variant_found_in_list = variant_found_in_string.split(\" | \")\n",
        "\n",
        "            variants_found_list = list(set(variants_found_list))\n",
        "            variants_found_string = \" | \".join(variants_found_list)\n",
        "\n",
        "            if len(variants_found_list) != 0:\n",
        "            \n",
        "              trial_rows.append(nct_id)\n",
        "              trial_rows.append(study_type)\n",
        "              trial_rows.append(study_purpose)\n",
        "              trial_rows.append(study_model)\n",
        "              trial_rows.append(overall_status)\n",
        "              trial_rows.append(phase)\n",
        "              trial_rows.append(rank)\n",
        "              trial_rows.append(gene_found_in)\n",
        "              trial_rows.append(gene_aliases_found)\n",
        "              trial_rows.append(variant_found_in_string)\n",
        "              trial_rows.append(variants_found_string)\n",
        "              trial_rows.append(\"Codon Match\")\n",
        "              trial_rows.append(brief_title)\n",
        "              trial_rows.append(official_title)\n",
        "              trial_rows.append(brief_summary)\n",
        "              trial_rows.append(detailed_description)\n",
        "              trial_rows.append(cancer_type)\n",
        "              trial_rows.append(intervention)\n",
        "              trial_rows.append(intervention_description)\n",
        "              trial_rows.append(intervention_other_name)\n",
        "              trial_rows.append(arm_title)\n",
        "              trial_rows.append(arm_description)\n",
        "              trial_rows.append(arm_group_intervention)\n",
        "              trial_rows.append(eligibility_criteria)\n",
        "              trial_rows.append(inclusion_criteria)\n",
        "              trial_rows.append(exclusion_criteria)\n",
        "              trial_rows.append(character_count)\n",
        "              trial_rows.append(primary_om_title)\n",
        "              trial_rows.append(primary_om_description)\n",
        "              trial_rows.append(secondary_om_title)\n",
        "              trial_rows.append(secondary_om_description)\n",
        "              trial_rows.append(other_om_title)\n",
        "              trial_rows.append(other_om_description)\n",
        "              trial_rows.append(keywords)\n",
        "              trial_rows.append(mesh_terms)\n",
        "              trial_rows.append(pmid)\n",
        "              trial_rows.append(url)\n",
        "              result_list.append(trial_rows)\n",
        "\n",
        "              count = count + 1\n",
        "      \n",
        "        variant, codon = variant.split(\"|\")\n",
        "        codon = f\"codon {codon}\"\n",
        "        codon = codon.lower()\n",
        "        trial_rows=[]\n",
        "        variant_found_in = []\n",
        "        variants_found_list = []\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), brief_title.lower())):\n",
        "          # print(\"found\", \"Brief Title\")\n",
        "          variant_found_in.append(f\"{codon} = Brief Title\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), official_title.lower())):\n",
        "          # print(\"found\", \"Official Title\")\n",
        "          variant_found_in.append(f\"{codon} = Official Title\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), brief_summary.lower())):\n",
        "          # print(\"found\", \"Brief Summary\")\n",
        "          variant_found_in.append(f\"{codon} = Brief Summary\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), detailed_description.lower())):\n",
        "          # print(\"found\", \"Detailed Description\")\n",
        "          variant_found_in.append(f\"{codon} = Detailed Description\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), cancer_type.lower())):\n",
        "          # print(\"found\", \"Cancer Type\")\n",
        "          variant_found_in.append(f\"{codon} = Cancer Type\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), intervention_description.lower())):\n",
        "          # print(\"found\", \"Intervention Description\")\n",
        "          variant_found_in.append(f\"{codon} = Intervention Description\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), arm_title.lower())):\n",
        "          # print(\"found\", \"Arm Title\")\n",
        "          variant_found_in.append(f\"{codon} = Arm Title\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), arm_description.lower())):\n",
        "          # print(\"found\", \"Arm Description\")\n",
        "          variant_found_in.append(f\"{codon} = Arm Description\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), eligibility_criteria.lower())):\n",
        "          # print(\"found\", \"Eligibility Criterial\")\n",
        "          variant_found_in.append(f\"{codon} = Eligibility Criteria\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), inclusion_criteria.lower())):\n",
        "          # print(\"found\", \"Inclusion Criteria\")\n",
        "          variant_found_in.append(f\"{codon} = Inclusion Criteria\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), exclusion_criteria.lower())):\n",
        "          # print(\"found\", \"Exclusion Criteria\")\n",
        "          variant_found_in.append(f\"{codon} = Exclusion Criteria\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), keywords.lower())):\n",
        "          # print(\"found\", \"Keywords\")\n",
        "          variant_found_in.append(f\"{codon} = Keywords\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), primary_om_title.lower())):\n",
        "          # print(\"found\", \"Primary OM Title\")\n",
        "          variant_found_in.append(f\"{codon} = Primary OM Title\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), primary_om_description.lower())):\n",
        "          # print(\"found\", \"Primary OM Description\")\n",
        "          variant_found_in.append(f\"{codon} = Primary OM Description\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), secondary_om_title.lower())):\n",
        "          # print(\"found\", \"Secondary OM Title\")\n",
        "          variant_found_in.append(f\"{codon} = Secondary OM Title\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), secondary_om_description.lower())):\n",
        "          # print(\"found\", \"Secondary OM Description\")\n",
        "          variant_found_in.append(f\"{codon} = Secondary OM Description\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), other_om_title.lower())):\n",
        "          # print(\"found\", \"Other OM Title\")\n",
        "          variant_found_in.append(f\"{codon} = Other OM Title\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), other_om_description.lower())):\n",
        "          # print(\"found\", \"Other OM Description\")\n",
        "          variant_found_in.append(f\"{codon} = Other OM Description\")\n",
        "          variants_found_list.append(variant)\n",
        "        if (re.findall(r\"\\b{}\\b\".format(codon), mesh_terms.lower())):\n",
        "          # print(\"found\", \"MeSH Terms\")\n",
        "          variant_found_in.append(f\"{codon} = MeSH Terms\")\n",
        "          variants_found_list.append(variant)\n",
        "\n",
        "        variant_found_in_string = \" | \".join(variant_found_in)\n",
        "        variant_found_in_list = variant_found_in_string.split(\" | \")\n",
        "\n",
        "        variants_found_list = list(set(variants_found_list))\n",
        "        variants_found_string = \" | \".join(variants_found_list)\n",
        "\n",
        "        if len(variants_found_list) != 0:\n",
        "        \n",
        "          trial_rows.append(nct_id)\n",
        "          trial_rows.append(study_type)\n",
        "          trial_rows.append(study_purpose)\n",
        "          trial_rows.append(study_model)\n",
        "          trial_rows.append(overall_status)\n",
        "          trial_rows.append(phase)\n",
        "          trial_rows.append(rank)\n",
        "          trial_rows.append(gene_found_in)\n",
        "          trial_rows.append(gene_aliases_found)\n",
        "          trial_rows.append(variant_found_in_string)\n",
        "          trial_rows.append(variants_found_string)\n",
        "          trial_rows.append(\"Codon Match\")\n",
        "          trial_rows.append(brief_title)\n",
        "          trial_rows.append(official_title)\n",
        "          trial_rows.append(brief_summary)\n",
        "          trial_rows.append(detailed_description)\n",
        "          trial_rows.append(cancer_type)\n",
        "          trial_rows.append(intervention)\n",
        "          trial_rows.append(intervention_description)\n",
        "          trial_rows.append(intervention_other_name)\n",
        "          trial_rows.append(arm_title)\n",
        "          trial_rows.append(arm_description)\n",
        "          trial_rows.append(arm_group_intervention)\n",
        "          trial_rows.append(eligibility_criteria)\n",
        "          trial_rows.append(inclusion_criteria)\n",
        "          trial_rows.append(exclusion_criteria)\n",
        "          trial_rows.append(character_count)\n",
        "          trial_rows.append(primary_om_title)\n",
        "          trial_rows.append(primary_om_description)\n",
        "          trial_rows.append(secondary_om_title)\n",
        "          trial_rows.append(secondary_om_description)\n",
        "          trial_rows.append(other_om_title)\n",
        "          trial_rows.append(other_om_description)\n",
        "          trial_rows.append(keywords)\n",
        "          trial_rows.append(mesh_terms)\n",
        "          trial_rows.append(pmid)\n",
        "          trial_rows.append(url)\n",
        "          result_list.append(trial_rows)\n",
        "\n",
        "          count = count + 1\n",
        "      \n",
        "      if count == 0:\n",
        "\n",
        "        trial_rows.append(nct_id)\n",
        "        trial_rows.append(study_type)\n",
        "        trial_rows.append(study_purpose)\n",
        "        trial_rows.append(study_model)\n",
        "        trial_rows.append(overall_status)\n",
        "        trial_rows.append(phase)\n",
        "        trial_rows.append(rank)\n",
        "        trial_rows.append(gene_found_in)\n",
        "        trial_rows.append(gene_aliases_found)\n",
        "        trial_rows.append(variant_found_in_string)\n",
        "        trial_rows.append(variants_found_string)\n",
        "        trial_rows.append(\"VNF\")\n",
        "        trial_rows.append(brief_title)\n",
        "        trial_rows.append(official_title)\n",
        "        trial_rows.append(brief_summary)\n",
        "        trial_rows.append(detailed_description)\n",
        "        trial_rows.append(cancer_type)\n",
        "        trial_rows.append(intervention)\n",
        "        trial_rows.append(intervention_description)\n",
        "        trial_rows.append(intervention_other_name)\n",
        "        trial_rows.append(arm_title)\n",
        "        trial_rows.append(arm_description)\n",
        "        trial_rows.append(arm_group_intervention)\n",
        "        trial_rows.append(eligibility_criteria)\n",
        "        trial_rows.append(inclusion_criteria)\n",
        "        trial_rows.append(exclusion_criteria)\n",
        "        trial_rows.append(character_count)\n",
        "        trial_rows.append(primary_om_title)\n",
        "        trial_rows.append(primary_om_description)\n",
        "        trial_rows.append(secondary_om_title)\n",
        "        trial_rows.append(secondary_om_description)\n",
        "        trial_rows.append(other_om_title)\n",
        "        trial_rows.append(other_om_description)\n",
        "        trial_rows.append(keywords)\n",
        "        trial_rows.append(mesh_terms)\n",
        "        trial_rows.append(pmid)\n",
        "        trial_rows.append(url)\n",
        "        result_list.append(trial_rows)\n",
        "        \n",
        "      # trial_rows.append(variant_found_in_string)\n",
        "      # trial_rows.append(drug_check_string)\n",
        "      # trial_rows.append(pathway_found_string)\n",
        "      # trial_rows.append(drug_not_found_string)\n",
        "      \n",
        "      # result_list.append(trial_rowsresult_list.append(trial_rows))\n",
        "\n",
        "    # result_list_df = pd.DataFrame(result_list, columns = [\"NCT ID\", \"Study Type\", \"Recruitment Status\", \"Phase\", \"Brief Title\", \"Official Title\", \"Brief Summary\", \"Detailed Description\", \"Cancer Type\", \"Study Purpose\", \"Intervention\", \"Intervention Description\", \"Intervention Other Name\", \"Study Model\", \"Arm Title\", \"Arm Description\", \"Arm Group Intervention\", \"Eligibility Criteria\", \"Inclusion Criteria\", \"Exclusion Criteria\", \"Keywords\", \"PMID\", \"URL\", \"Primary OM Title\", \"Primary OM Description\", \"Secondary OM Title\", \"Secondary OM Description\", \"Other OM Title\", \"Other OM Description\", \"MeSH Terms\", \"Character Count\", \"Gene Found In\", \"Rank\", \"Drug Match\", \"Pathway Match\", \"Drug Not Found\"])\n",
        "    result_list_df = pd.DataFrame(result_list, columns = ['NCT ID', 'Study Type', 'Study Purpose', 'Study Model', 'Recruitment Status', 'Phase', 'Level', 'Gene Found In', 'Gene Aliases Found', 'Variant Found In', 'Variants Found', 'Variant Match Type', 'Brief Title', 'Official Title', 'Brief Summary', 'Detailed Description', 'Cancer Type', 'Intervention', 'Intervention Description', 'Intervention Other Name', 'Arm Title', 'Arm Description', 'Arm Group Intervention', 'Eligibility Criteria', 'Inclusion Criteria', 'Exclusion Criteria', 'Character Count', 'Primary OM Title', 'Primary OM Description', 'Secondary OM Title', 'Secondary OM Description', 'Other OM Title', 'Other OM Description', 'Keywords', 'MeSH Terms', 'PMID', 'URL'])\n",
        "    # result_list_df = result_list_df[result_list_df['Gene Found In'] != \"\"]\n",
        "    return result_list_df\n",
        "  else:\n",
        "    return sheet_df\n"
      ],
      "metadata": {
        "id": "ikpZL1oqUT9y"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def rowsplit(indata, col, sep):\n",
        "#   s = indata.assign(variant_found=indata[col].str.split(\n",
        "#         sep)).explode('Variants Found')\n",
        "  \n",
        "#   indata.drop(columns=[col], inplace=True)\n",
        "#   # print(indata)\n",
        "#   i = s.index.get_level_values(0)\n",
        "#   # print(i)\n",
        "#   indata = indata.loc[i].copy()\n",
        "#   # print(indata)\n",
        "#   indata[\"Variants Found\"] = s['Variants Found']\n",
        "#   # print(indata)\n",
        "#   return indata\n"
      ],
      "metadata": {
        "id": "Q_n4O1Q1RIh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report(result_df, gene):\n",
        "  final_report_list = []\n",
        "  df_1a = result_df[result_df['Level'] == \"1A\"]\n",
        "  df_1b = result_df[result_df['Level'] == \"1B\"]\n",
        "  df_1c = result_df[result_df['Level'] == \"1C\"]\n",
        "\n",
        "  report_df = pd.concat([df_1a, df_1b, df_1c])\n",
        "\n",
        "  for index in report_df.index:\n",
        "    trial_rows=[]\n",
        "    data_df = report_df.loc[index]\n",
        "\n",
        "    nct_id = data_df['NCT ID']\n",
        "    phase = data_df['Phase']\n",
        "    official_title = data_df['Official Title']\n",
        "    intervention = data_df['Intervention']\n",
        "    level = data_df['Level']\n",
        "    cancer_type = data_df['Cancer Type']\n",
        "    study_type = data_df['Study Type']\n",
        "    pmid = data_df['PMID']\n",
        "    url = data_df['URL']\n",
        "\n",
        "    concatenated_string = f\"{nct_id} | {phase} | {official_title}\"\n",
        "\n",
        "    trial_rows.append(gene)\n",
        "    trial_rows.append(concatenated_string)\n",
        "    trial_rows.append(intervention)\n",
        "    trial_rows.append(level)\n",
        "    trial_rows.append(nct_id)\n",
        "    trial_rows.append(cancer_type)\n",
        "    trial_rows.append(pmid)\n",
        "    trial_rows.append(study_type)\n",
        "    trial_rows.append(url)\n",
        "    \n",
        "    final_report_list.append(trial_rows)\n",
        "  \n",
        "  final_report_df = pd.DataFrame(final_report_list, columns = ['Gene', 'Concatenated String', 'Intervention', 'Level', 'NCT ID', 'Cancer Type', 'PMID', 'Study Type', 'URL'])\n",
        "  # result_list_df = result_list_df[result_list_df['Gene Found In'] != \"\"]\n",
        "  \n",
        "  return final_report_df\n"
      ],
      "metadata": {
        "id": "Ai-KH0bLguql"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_sheet(result_df, sheet_name, data_to_write, headers):\n",
        "  today = date.today()\n",
        "  sh = gc.open(f\"{gene}-exactVariantMatch-{today}-try8\")\n",
        "  worksheet = sh.worksheet(sheet_name)\n",
        "  print(\"started\")\n",
        "  try:\n",
        "    worksheet.append_rows(data_to_write, value_input_option='USER_ENTERED', insert_data_option=None, table_range=None, include_values_in_response=False)\n",
        "  except gspread.exceptions.APIError:\n",
        "    worksheet = sh.add_worksheet(title=f\"sheet_name\"+1, rows=\"10000\", col=\"50\")\n",
        "    worksheet.update(\"A1\",headers,value_input_option=\"USER_ENTERED\")\n",
        "    worksheet.append_rows(data_to_write, value_input_option='USER_ENTERED', insert_data_option=None, table_range=None, include_values_in_response=False)\n",
        "  print(\"write completed\")\n",
        "  worksheet.format(\"1:100000\", {\n",
        "  \n",
        "    \"horizontalAlignment\": \"LEFT\",\n",
        "    \"verticalAlignment\": \"TOP\",\n",
        "    \"wrapStrategy\": \"CLIP\",\n",
        "    \n",
        "  })\n",
        "\n",
        "  set_row_heights(worksheet, [ ('1:100000', 21), ('101:', 21) ])\n",
        "  set_column_width(worksheet, 'A:AL', 200)"
      ],
      "metadata": {
        "id": "jA2OcXL1fBkY"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def update_spreadsheet(result_df, gene, sheet_name):\n",
        "  today = date.today()\n",
        "  sh = gc.open(f\"{gene}-exactVariantMatch-{today}-try8\")\n",
        "  worksheet = sh.add_worksheet(title=sheet_name, rows=\"10000\", cols=\"38\")\n",
        "\n",
        "  data_list = result_df.to_numpy().tolist()\n",
        "  headers = result_df.columns.tolist()\n",
        "  headers = [headers]\n",
        "  worksheet.update(\"A1\",headers,value_input_option=\"USER_ENTERED\")\n",
        "\n",
        "  end_limit = result_df.shape[0]\n",
        "  print(\"completed\")\n",
        "\n",
        "  min_value = 0\n",
        "  max_value = 999\n",
        "\n",
        "  while max_value <= end_limit:\n",
        "    data_to_write = data_list[min_value:max_value+1]\n",
        "    update_sheet(result_df, sheet_name, data_to_write, headers)\n",
        "\n",
        "    min_value += 1000\n",
        "    max_value += 1000\n",
        "  if max_value != end_limit:\n",
        "    min_value = min_value\n",
        "    max_value = end_limit\n",
        "    data_to_write = data_list[min_value:max_value+1]\n",
        "    update_sheet(result_df, sheet_name, data_to_write, headers)"
      ],
      "metadata": {
        "id": "sCkYWsVrfC3l"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interventional_trial_ss = gc.open_by_key(\"1cjT64UTRr8IDNATjeufEoebQN2k_vyCJU3eQkfbXYTo\")\n",
        "\n",
        "final_list = []\n",
        "sheet_names = interventional_trial_ss.worksheets()\n",
        "for sheet in sheet_names:\n",
        "  \n",
        "  rows = sheet.get_all_values()\n",
        "  df = pd.DataFrame.from_records(rows[1:], columns=rows[0])\n",
        "  final_list.append(df)"
      ],
      "metadata": {
        "id": "baUaZw4RfTGf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df1 = pd.concat(final_list)\n",
        "combined_df1.shape"
      ],
      "metadata": {
        "id": "w9PsPlmAfWGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4712386-4ec0-4ec3-919b-57e5023831c6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80316, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observational_trial_ss = gc.open_by_key(\"1MlFhdqcwAa7Al1OPoe_3VnQ2kqQZ5-baG1-SWTW94xM\")\n",
        "\n",
        "final_list = []\n",
        "sheet_names = observational_trial_ss.worksheets()\n",
        "for sheet in sheet_names:\n",
        "  if sheet.title != \"Sheet1\":\n",
        "    rows = sheet.get_all_values()\n",
        "    df = pd.DataFrame.from_records(rows[1:], columns=rows[0])\n",
        "    final_list.append(df)"
      ],
      "metadata": {
        "id": "HSsFCPPafX8k"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df2 = pd.concat(final_list)\n",
        "combined_df2.shape"
      ],
      "metadata": {
        "id": "9xfJkD6Afa0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571bd22f-77c5-4a4d-f821-be33fc047783"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19147, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "expanded_trial_ss = gc.open_by_key(\"1hVXkqX_GBagL_PNTaqP-oFZ-4KaSUp5FwQBgXSzzvvA\")\n",
        "\n",
        "final_list = []\n",
        "sheet_names = expanded_trial_ss.worksheets()\n",
        "for sheet in sheet_names:\n",
        "  if sheet.title != \"Sheet1\":\n",
        "    rows = sheet.get_all_values()\n",
        "    df = pd.DataFrame.from_records(rows[1:], columns=rows[0])\n",
        "    final_list.append(df)"
      ],
      "metadata": {
        "id": "NRTZemmFfdKN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df3 = pd.concat(final_list)\n",
        "combined_df3.shape"
      ],
      "metadata": {
        "id": "9txFA9ixff3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c21327-f547-48ea-cc82-b233e4457031"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(367, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_combined_df = pd.concat([combined_df1, combined_df2, combined_df3])\n",
        "final_combined_df.set_index('NCT ID', inplace=True)\n",
        "final_combined_df.reset_index(level=0, inplace=True)\n",
        "final_combined_df.shape"
      ],
      "metadata": {
        "id": "5oeN13okfjQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294a5a5d-374e-4b90-bd8c-1f8caf2312f0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99830, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_found_df = find_cancer_nct_id(final_combined_df)"
      ],
      "metadata": {
        "id": "HxLUE3iUTG7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curate_genes_ss = gc.open_by_key(\"1jE7-Z9CGln7drOUnyFXO4cBwvu71I-SKKdaIL0xPvO8\")\n",
        "curate_genes_ws = curate_genes_ss.worksheet(\"InputGeneList\")\n",
        "rows = curate_genes_ws.get_all_values()\n",
        "curate_genes_df = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "genes_list = curate_genes_df['exact match'].to_numpy().tolist()\n",
        "genes_list"
      ],
      "metadata": {
        "id": "_ableMh7fmJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "feEbnQxUgE3l"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genes_list = [\"KRAS\"]\n",
        "\n",
        "for gene in genes_list:\n",
        "\n",
        "  start = time.time()\n",
        "  # result_list_df = pd.DataFrame(result_list, columns = ['NCT ID', 'Study Type', 'Study Purpose', 'Study Model', 'Recruitment Status', 'Phase', 'Level', 'Gene Found In', 'Gene Aliases Found', 'Variant Found In', 'Variants Found', 'Brief Title', 'Official Title', 'Brief Summary', 'Detailed Description', 'Cancer Type', 'Intervention', 'Intervention Description', 'Intervention Other Name', 'Arm Title', 'Arm Description', 'Arm Group Intervention', 'Eligibility Criteria', 'Inclusion Criteria', 'Exclusion Criteria', 'Character Count', 'Primary OM Title', 'Primary OM Description', 'Secondary OM Title', 'Secondary OM Description', 'Other OM Title', 'Other OM Description', 'Keywords', 'MeSH Terms', 'PMID', 'URL'])\n",
        "  result_df = pd.DataFrame(columns = ['NCT ID', 'Study Type', 'Study Purpose', 'Study Model', 'Recruitment Status', 'Phase', 'Level', 'Gene Found In', 'Gene Aliases Found', 'Variant Match Type', 'Brief Title', 'Official Title', 'Brief Summary', 'Detailed Description', 'Cancer Type', 'Intervention', 'Intervention Description', 'Intervention Other Name', 'Arm Title', 'Arm Description', 'Arm Group Intervention', 'Eligibility Criteria', 'Inclusion Criteria', 'Exclusion Criteria', 'Character Count', 'Primary OM Title', 'Primary OM Description', 'Secondary OM Title', 'Secondary OM Description', 'Other OM Title', 'Other OM Description', 'Keywords', 'MeSH Terms', 'PMID', 'URL'])\n",
        "  variant_result_df = pd.DataFrame(columns = ['NCT ID', 'Study Type', 'Study Purpose', 'Study Model', 'Recruitment Status', 'Phase', 'Level', 'Gene Found In', 'Gene Aliases Found', 'Variant Found In', 'Variants Found', 'Variant Match Type', 'Brief Title', 'Official Title', 'Brief Summary', 'Detailed Description', 'Cancer Type', 'Intervention', 'Intervention Description', 'Intervention Other Name', 'Arm Title', 'Arm Description', 'Arm Group Intervention', 'Eligibility Criteria', 'Inclusion Criteria', 'Exclusion Criteria', 'Character Count', 'Primary OM Title', 'Primary OM Description', 'Secondary OM Title', 'Secondary OM Description', 'Other OM Title', 'Other OM Description', 'Keywords', 'MeSH Terms', 'PMID', 'URL'])\n",
        "\n",
        "  final_combined_df = final_combined_df[final_combined_df['Recruitment Status'] != \"Terminated\"]\n",
        "  final_combined_df = final_combined_df[final_combined_df['Recruitment Status'] != \"Suspended\"]\n",
        "  final_combined_df = final_combined_df[final_combined_df['Recruitment Status'] != \"Unknown status\"]\n",
        "  final_combined_df = final_combined_df[final_combined_df['Recruitment Status'] != \"Withdrawn\"]\n",
        "\n",
        "  #get gene names\n",
        "  gene_names = get_gene_aliases_from_master_genes(gene)\n",
        "  gene_names.append(gene)\n",
        "  gene_names = list(set(gene_names))\n",
        "  gene_alias_used = \" | \".join(gene_names)\n",
        "\n",
        "  final_df = filter_gene_found_in(sheet_df=final_combined_df, gene_names=gene_names)\n",
        "  result_df = result_df.append(final_df)\n",
        "  \n",
        "  variant_df = variant_exact_match(sheet_df=result_df, gene=gene)\n",
        "  variant_result_df1 = variant_result_df.append(variant_df)\n",
        "\n",
        "  variant_exact_df = variant_df[variant_df['Variant Match Type'] == \"Exact Match\"]\n",
        "  variant_vnf_df = variant_df[variant_df['Variant Match Type'] == \"VNF\"]\n",
        "\n",
        "  variant_df = missense_codon_match(sheet_df=variant_vnf_df, gene=gene)\n",
        "  variant_result_df2 = variant_result_df.append(variant_df)\n",
        "\n",
        "  variant_codon_df = variant_df[variant_df['Variant Match Type'] == \"Codon Match\"]\n",
        "  variant_vnf_df = variant_df[variant_df['Variant Match Type'] == \"VNF\"]\n",
        "\n",
        "  variant_df = deletion_codon_match(sheet_df=variant_vnf_df, gene=gene)\n",
        "  variant_result_df2 = variant_result_df.append(variant_df)\n",
        "\n",
        "  result_df = pd.concat([variant_exact_df, variant_codon_df])\n",
        "\n",
        "  total_ids = result_df.shape[0]\n",
        "  level_1a_count = result_df[result_df['Level'] == \"1A\"].shape[0]\n",
        "  level_1b_count = result_df[result_df['Level'] == \"1B\"].shape[0]\n",
        "  level_1c_count = result_df[result_df['Level'] == \"1C\"].shape[0]\n",
        "  level_2_count = result_df[result_df['Level'] == \"2\"].shape[0]\n",
        "  level_3_count = result_df[result_df['Level'] == \"3\"].shape[0]\n",
        "\n",
        "  gene_alias_found_list = result_df['Gene Aliases Found'].to_numpy().tolist()\n",
        "  gene_alias_found_list = list(set(gene_alias_found_list))\n",
        "  \n",
        "  gene_alias_found_in_trial_list = []\n",
        "  for alias in gene_alias_found_list:\n",
        "    if \"|\" in alias:\n",
        "      data = alias.split(\" | \")\n",
        "      for gene_value in data:\n",
        "        gene_alias_found_in_trial_list.append(gene_value)\n",
        "    else:\n",
        "      gene_alias_found_in_trial_list.append(alias)\n",
        "\n",
        "  gene_alias_found_in_trial_list = list(set(gene_alias_found_in_trial_list))\n",
        "\n",
        "  gene_alias_found_in_trial_string = \" | \".join(gene_alias_found_in_trial_list)\n",
        "  today = date.today()\n",
        "  # print(today)\n",
        "\n",
        "  new_ss = gc.create(f\"{gene}-exactVariantMatch-{today}-try7\", \"17x4-h4WPSOPPwdCdX9x595xBh6NknAXr\")\n",
        "  ws = new_ss.sheet1\n",
        "  ws.update_title(\"Overview\")\n",
        "  \n",
        "  ws.update(f\"B3\", \"Gene Name\")\n",
        "  ws.update(f\"C3\", gene)\n",
        "  ws.update(f\"B4\", \"Gene Aliases Used to retrieve trials\")\n",
        "  ws.update(f\"C4\", gene_alias_used)\n",
        "  ws.update(f\"B5\", \"Gene Aliases found in trials\")\n",
        "  ws.update(f\"C5\", gene_alias_found_in_trial_string)\n",
        "  ws.update(f\"B6\", \"Total Count\")\n",
        "  ws.update(f\"C6\", total_ids)\n",
        "\n",
        "  update_spreadsheet(result_df, gene, \"Combined-Result\")\n",
        "\n",
        "  study_list = ['Interventional', 'Observational', 'Expanded Access', 'Patient Registry']\n",
        "  level_list = ['1A', '1B', '1C', '2', '3']\n",
        "\n",
        "  count = 8\n",
        "  for study in study_list:\n",
        "    df = result_df[result_df['Study Type'] == study]\n",
        "    total_value = df.shape[0]\n",
        "    ws.update(f\"B{count}\", f\"{study} Studies\")\n",
        "    ws.update(f\"C{count}\", total_value)\n",
        "\n",
        "    update_spreadsheet(df, gene, study)\n",
        "    count = count+1\n",
        "\n",
        "  count = 13\n",
        "  for level in level_list:\n",
        "    df = result_df[result_df['Level'] == level]\n",
        "    total_value = df.shape[0]\n",
        "    ws.update(f\"B{count}\", f\"Level {level} trial\")\n",
        "    ws.update(f\"C{count}\", total_value)\n",
        "    update_spreadsheet(df, gene, f\"level {level}\")\n",
        "    count = count+1\n",
        "  \n",
        "  report_df = generate_report(result_df, gene)\n",
        "  update_spreadsheet(report_df, gene, \"Report\")\n",
        "\n",
        "  ws.format(\"1:10000\", {\n",
        "  \n",
        "    \"horizontalAlignment\": \"LEFT\",\n",
        "    \"verticalAlignment\": \"TOP\",\n",
        "    \"wrapStrategy\": \"WRAP\",\n",
        "    \n",
        "  })\n",
        "\n",
        "  \n",
        "  set_column_width(ws, 'A:AL', 250)\n",
        "\n",
        "  end = time.time()\n",
        "  time_taken = (end - start) // 60\n",
        "  # print(f\"{gene}  completed in {time_taken} minutes \")\n",
        "  print(gene, \"\\t completed in \", time_taken, \" minutes\",\"\\t\",total_ids, \"\\t 1A: \", level_1a_count, \"\\t 1B: \", level_1b_count, \"\\t 1C: \", level_1c_count, \"\\t 2: \", level_2_count, \"\\t 3: \", level_3_count, \"\\t GeneAlias: \", gene_alias_found_in_trial_string)"
      ],
      "metadata": {
        "id": "-C2_VyHqfo9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "8879f1c7-4677-4a56-8621-0c5cb8d28541"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-470c7a201462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0mreport_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m   \u001b[0mupdate_spreadsheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Report\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   ws.format(\"1:10000\", {\n",
            "\u001b[0;32m<ipython-input-61-a71ed7e3c8d2>\u001b[0m in \u001b[0;36mupdate_spreadsheet\u001b[0;34m(result_df, gene, sheet_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mend_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdata_to_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mupdate_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_to_write\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmin_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-32dc6871007b>\u001b[0m in \u001b[0;36mupdate_sheet\u001b[0;34m(result_df, sheet_name, data_to_write, headers)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mworksheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mworksheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_write\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_input_option\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'USER_ENTERED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_data_option\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_values_in_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mworksheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_worksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"sheet_name\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"10000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"50\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gspread/worksheet.py\u001b[0m in \u001b[0;36mappend_rows\u001b[0;34m(self, values, value_input_option, insert_data_option, table_range, include_values_in_response)\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspreadsheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minsert_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_input_option\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mValueInputOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gspread/spreadsheet.py\u001b[0m in \u001b[0;36mvalues_append\u001b[0;34m(self, range, params, body)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[1;32m    148\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSPREADSHEET_VALUES_APPEND_URL\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gspread/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, params, data, json, files, headers)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         )\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \"\"\"\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         \u001b[0mremaining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_body\u001b[0;34m(self, data, files, json)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;31m# provides this natively, but Python 3 gives a Unicode string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'application/json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Object of type Series is not JSON serializable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.concat([variant_exact_df, variant_result_df2])\n",
        "\n",
        "total_ids = result_df.shape[0]\n",
        "level_1a_count = result_df[result_df['Level'] == \"1A\"].shape[0]\n",
        "level_1b_count = result_df[result_df['Level'] == \"1B\"].shape[0]\n",
        "level_1c_count = result_df[result_df['Level'] == \"1C\"].shape[0]\n",
        "level_2_count = result_df[result_df['Level'] == \"2\"].shape[0]\n",
        "level_3_count = result_df[result_df['Level'] == \"3\"].shape[0]\n",
        "\n",
        "gene_alias_found_list = result_df['Gene Aliases Found'].to_numpy().tolist()\n",
        "gene_alias_found_list = list(set(gene_alias_found_list))\n",
        "\n",
        "gene_alias_found_in_trial_list = []\n",
        "for alias in gene_alias_found_list:\n",
        "  if \"|\" in alias:\n",
        "    data = alias.split(\" | \")\n",
        "    for gene_value in data:\n",
        "      gene_alias_found_in_trial_list.append(gene_value)\n",
        "  else:\n",
        "    gene_alias_found_in_trial_list.append(alias)\n",
        "\n",
        "gene_alias_found_in_trial_list = list(set(gene_alias_found_in_trial_list))\n",
        "\n",
        "gene_alias_found_in_trial_string = \" | \".join(gene_alias_found_in_trial_list)\n",
        "today = date.today()\n",
        "# print(today)\n",
        "\n",
        "new_ss = gc.create(f\"{gene}-exactVariantMatch-{today}-try6\", \"17x4-h4WPSOPPwdCdX9x595xBh6NknAXr\")\n",
        "ws = new_ss.sheet1\n",
        "ws.update_title(\"Overview\")\n",
        "\n",
        "ws.update(f\"B3\", \"Gene Name\")\n",
        "ws.update(f\"C3\", gene)\n",
        "ws.update(f\"B4\", \"Gene Aliases Used to retrieve trials\")\n",
        "ws.update(f\"C4\", gene_alias_used)\n",
        "ws.update(f\"B5\", \"Gene Aliases found in trials\")\n",
        "ws.update(f\"C5\", gene_alias_found_in_trial_string)\n",
        "ws.update(f\"B6\", \"Total Count\")\n",
        "ws.update(f\"C6\", total_ids)\n",
        "\n",
        "update_spreadsheet(result_df, gene, \"Combined-Result\")\n",
        "\n",
        "study_list = ['Interventional', 'Observational', 'Expanded Access', 'Patient Registry']\n",
        "level_list = ['1A', '1B', '1C', '2', '3']\n",
        "\n",
        "count = 8\n",
        "for study in study_list:\n",
        "  df = result_df[result_df['Study Type'] == study]\n",
        "  total_value = df.shape[0]\n",
        "  ws.update(f\"B{count}\", f\"{study} Studies\")\n",
        "  ws.update(f\"C{count}\", total_value)\n",
        "\n",
        "  update_spreadsheet(df, gene, study)\n",
        "  count = count+1\n",
        "\n",
        "count = 13\n",
        "for level in level_list:\n",
        "  df = result_df[result_df['Level'] == level]\n",
        "  total_value = df.shape[0]\n",
        "  ws.update(f\"B{count}\", f\"Level {level} trial\")\n",
        "  ws.update(f\"C{count}\", total_value)\n",
        "  update_spreadsheet(df, gene, f\"level {level}\")\n",
        "  count = count+1\n",
        "\n",
        "report_df = generate_report(result_df, gene)\n",
        "update_spreadsheet(report_df, gene, \"Report\")\n",
        "\n",
        "ws.format(\"1:10000\", {\n",
        "\n",
        "  \"horizontalAlignment\": \"LEFT\",\n",
        "  \"verticalAlignment\": \"TOP\",\n",
        "  \"wrapStrategy\": \"WRAP\",\n",
        "  \n",
        "})\n",
        "\n",
        "\n",
        "set_column_width(ws, 'A:AL', 250)\n",
        "\n",
        "end = time.time()\n",
        "time_taken = (end - start) // 60\n",
        "# print(f\"{gene}  completed in {time_taken} minutes \")\n",
        "print(gene, \"\\t completed in \", time_taken, \" minutes\",\"\\t\",total_ids, \"\\t 1A: \", level_1a_count, \"\\t 1B: \", level_1b_count, \"\\t 1C: \", level_1c_count, \"\\t 2: \", level_2_count, \"\\t 3: \", level_3_count, \"\\t GeneAlias: \", gene_alias_found_in_trial_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "9JwrqzUfjVqY",
        "outputId": "a5dd2250-eceb-419c-c8fb-c39b2b9dcf22"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-9f463ffe8890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mreport_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mupdate_spreadsheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Report\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m ws.format(\"1:10000\", {\n",
            "\u001b[0;32m<ipython-input-37-cd7b11f1645b>\u001b[0m in \u001b[0;36mupdate_spreadsheet\u001b[0;34m(result_df, gene, sheet_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mend_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdata_to_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mupdate_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_to_write\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmin_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-f710d71bb6a3>\u001b[0m in \u001b[0;36mupdate_sheet\u001b[0;34m(result_df, sheet_name, data_to_write, headers)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mworksheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mworksheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_write\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_input_option\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'USER_ENTERED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_data_option\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_values_in_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mworksheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_worksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"sheet_name\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"10000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"50\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gspread/worksheet.py\u001b[0m in \u001b[0;36mappend_rows\u001b[0;34m(self, values, value_input_option, insert_data_option, table_range, include_values_in_response)\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspreadsheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minsert_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_input_option\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mValueInputOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gspread/spreadsheet.py\u001b[0m in \u001b[0;36mvalues_append\u001b[0;34m(self, range, params, body)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[1;32m    148\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSPREADSHEET_VALUES_APPEND_URL\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gspread/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, params, data, json, files, headers)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         )\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \"\"\"\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         \u001b[0mremaining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_body\u001b[0;34m(self, data, files, json)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;31m# provides this natively, but Python 3 gives a Unicode string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'application/json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Object of type Series is not JSON serializable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\"Test1\": ['Hi How are you', 'this is a Codons Check', 'this is a codons check'], \"Test2\": ['This is a codons check', 'Codon check issue', \"no value\"]}\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "SSHSh9HiU7R3",
        "outputId": "64ae6ef7-9c50-4031-be06-51883ea76abc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Test1                   Test2\n",
              "0          Hi How are you  This is a codons check\n",
              "1  this is a Codons Check       Codon check issue\n",
              "2  this is a codons check                no value"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a851c98f-85be-45ab-9c0b-90d9519ddbe3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test1</th>\n",
              "      <th>Test2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi How are you</td>\n",
              "      <td>This is a codons check</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is a Codons Check</td>\n",
              "      <td>Codon check issue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this is a codons check</td>\n",
              "      <td>no value</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a851c98f-85be-45ab-9c0b-90d9519ddbe3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a851c98f-85be-45ab-9c0b-90d9519ddbe3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a851c98f-85be-45ab-9c0b-90d9519ddbe3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace(to_replace=\"codons\", value=\"codon\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "Y4GFN4EYVlg_",
        "outputId": "4c0e32c2-6ba7-4e82-e27f-5e83e8dd793f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Test1                   Test2\n",
              "0          Hi How are you  This is a codons check\n",
              "1  this is a Codons Check       Codon check issue\n",
              "2   this is a codon check                no value"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cf97c64-cf27-4f77-ad9d-b3b01391e486\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test1</th>\n",
              "      <th>Test2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi How are you</td>\n",
              "      <td>This is a codons check</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this is a Codons Check</td>\n",
              "      <td>Codon check issue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this is a codon check</td>\n",
              "      <td>no value</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cf97c64-cf27-4f77-ad9d-b3b01391e486')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cf97c64-cf27-4f77-ad9d-b3b01391e486 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cf97c64-cf27-4f77-ad9d-b3b01391e486');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index in df.index:\n",
        "  data_df = df.loc[index]\n",
        "  test1 = data_df['Test1']\n",
        "print(test1)\n",
        "final = test1.replace(\"dfgdgfdg\", \"codon\")\n",
        "print(final)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKhgPqC8V9SM",
        "outputId": "60fe17cb-5e71-4cca-c966-cd32be758281"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is a codons check\n",
            "this is a codons check\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "variant_sh = gc.open_by_key(\"1_hKejRNMKYEf4jPQYSvzJZZUHIm-eNDDcuyc8LB6L5M\")\n",
        "variant_sheet = variant_sh.worksheet('DummyData')\n",
        "variant_rows = variant_sheet.get_all_values()\n",
        "\n",
        "variant_df = pd.DataFrame(variant_rows[1:], columns=variant_rows[0])\n",
        "\n",
        "data = variant_df.loc[(variant_df.Gene == gene)]\n",
        "variant_names = data['Variant'].to_numpy().tolist()\n",
        "codon_names = data['Codon'].to_numpy().tolist()\n",
        "# print(variant_names)\n",
        "# print(codon_names)\n",
        "\n",
        "i = 0\n",
        "final_list = []\n",
        "for i in range(len(variant_names)):\n",
        "  variant = f\"{variant_names[i]}|{codon_names[i]}\"\n",
        "  final_list.append(variant)\n",
        "\n",
        "print(final_list)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR0Hn2paWg1M",
        "outputId": "cf7c06d9-12a3-494a-90b9-6807fc078c5f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A146T|146', 'D153V|153', 'K147E|147', 'Y71H|71', 'A146V|146', 'N116H|116', 'T50I|50', 'Y40A|40', 'A146P|146', 'A59G|59', 'C118S|118', 'D154Q|154', 'D33E|33', 'E62K|62', 'F156L|156', 'F28L|28', 'G12A|12', 'G12C|12', 'G12D|12', 'G12F|12', 'G12R|12', 'G12S|12', 'G12V|12', 'G13C|13', 'G13D|13', 'G60R|60', 'K5N|5', 'L19F|19', 'N116S|116', 'P34L|34', 'P34R|34', 'Q22E|22', 'Q22K|22', 'Q22R|22', 'Q61H|61', 'Q61L|61', 'T58I|58', 'T74P|74', 'V14I|14', 'V14L|14', 'A66T|66', 'A66V|66', 'E31D|31', 'E63K|63', 'G12E|12', 'G12I|12', 'G12L|12', 'G12N|12', 'G12W|12', 'G12Y|12', 'G13V|13', 'G75E|75', 'K117N|117', 'Q61A|61', 'Q61E|61', 'Q61K|61', 'Q61P|61', 'Q61R|61', 'D57N|57', 'R164Q|164', 'A11P|11', 'A11T|11', 'A11V|11', 'A146G|146', 'A146X|146', 'A18D|18', 'A18V|18', 'A59E|59', 'A59S|59', 'A59T|59', 'A59X|59', 'D119N|119', 'D92Y|\\xa0', 'E31K|31', 'E49K|49', 'E62G|62', 'G12X|12', 'G138V|138', 'G13A|13', 'G13E|13', 'G13R|13', 'G13S|13', 'G13X|13', 'G15S|15', 'G15X|15', 'G60D|60', 'G60E|60', 'H95D|95', 'H95Q|95', 'H95R|95', 'I24L|24', 'I24N|24', 'I36L|36', 'I36M|36', 'I93F|93', 'K117X|117', 'K147N|147', 'K147T|147', 'K176Q|176', 'K5E|5', 'L23R|23', 'M72I|72', 'P110H|110', 'P110S|110', 'P121H|121', 'P140H|140', 'Q25H|25', 'Q61X|61', 'Q99L|99', 'R135T|135', 'R149G|149', 'R68M|68', 'R68S|68', 'R73M|73', 'R97I|97', 'S17T|17', 'T158A|158', 'T20R|20', 'V152G|152', 'V160A|160', 'V8E|8', 'V9I|9', 'Y32S|32', 'Y64A|64', 'Y64D|64', 'Y64H|64', 'Y64N|64', 'Y96C|96', 'Y96D|96', 'Y96S|96']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "variant = \"A146T|146\"\n",
        "variant, codon = variant.split(\"|\")\n",
        "print(variant)\n",
        "# print(codon)/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhdZferooOaX",
        "outputId": "5ce69d9a-a3d3-42d9-ff1c-83042d26ffb3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A146T\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update_spreadsheet(report_df, gene, \"Report1\")\n",
        "report_df"
      ],
      "metadata": {
        "id": "MSliDwBppBsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variant_sh = gc.open_by_key(\"1_hKejRNMKYEf4jPQYSvzJZZUHIm-eNDDcuyc8LB6L5M\")\n",
        "variant_sheet = variant_sh.worksheet('DummyData')\n",
        "variant_rows = variant_sheet.get_all_values()\n",
        "\n",
        "variant_df = pd.DataFrame(variant_rows[1:], columns=variant_rows[0])\n",
        "\n",
        "data = variant_df.loc[(variant_df.Gene == gene)]\n",
        "variant_names = data['Variant'].to_numpy().tolist()\n",
        "codon_names = data['Codon'].to_numpy().tolist()\n",
        "# print(variant_names)\n",
        "codon_names"
      ],
      "metadata": {
        "id": "UJ0fe5Kyxa15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variant_sh = gc.open_by_key(\"1_hKejRNMKYEf4jPQYSvzJZZUHIm-eNDDcuyc8LB6L5M\")\n",
        "variant_sheet = variant_sh.worksheet('DummyData')\n",
        "variant_rows = variant_sheet.get_all_values()\n",
        "\n",
        "variant_df = pd.DataFrame(variant_rows[1:], columns=variant_rows[0])\n",
        "\n",
        "variant_df = variant_df[variant_df['Impact'] == \"duplication\"]\n",
        "\n",
        "data = variant_df.loc[(variant_df.Gene == gene)]\n",
        "\n",
        "variants = data['Variant'].to_numpy().tolist()\n",
        "# print(variants)\n",
        "variant_names = []\n",
        "for variant in variants:\n",
        "  if \"_\" in variant:\n",
        "    codon1, codon2 = variant.split(\"dup\")[0].split(\"_\")\n",
        "    codon1 = codon1 + \"dup\"\n",
        "    codon2 = codon2 + \"dup\"\n",
        "    codon1 = codon1.split(\"dup\")[0][1:]\n",
        "    codon2 = codon2.split(\"dup\")[0][1:]\n",
        "    variant_name = f\"{variant}|{codon1}|{codon2}\"\n",
        "    variant_names.append(variant_name)\n",
        "  else:\n",
        "    codon = variant.split(\"dup\")[0][1:]\n",
        "    variant_name = f\"{variant}|{codon}\"\n",
        "    variant_names.append(variant_name)\n",
        "variant_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVSblC1-cfAe",
        "outputId": "606e09cc-28e4-43f6-edb1-2af0570d17bf"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A11_G12dup|11|12',\n",
              " 'G10dup|10',\n",
              " 'G12_G13dup|12|13',\n",
              " 'G12dup|12',\n",
              " 'G13dup|13',\n",
              " 'exon dup|xon ']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for variant in variant_names: #a, b\n",
        "  if \"_\" in variant:\n",
        "    for data in variant.split(\"|\"):\n",
        "      \n",
        "  variant, codon = variant.split(\"|\")\n",
        "  codon = f\"codon {codon}\"\n",
        "  codon = codon.lower()\n",
        "  trial_rows=[]\n",
        "  variant_found_in = []\n",
        "  variants_found_list = []"
      ],
      "metadata": {
        "id": "DEknVRQQiQnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}